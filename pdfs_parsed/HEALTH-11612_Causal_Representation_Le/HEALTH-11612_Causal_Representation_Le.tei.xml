<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">CAUSAL REPRESENTATION LEARNING FROM MULTI-MODAL BIOMEDICAL OBSERVATIONS</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yuewen</forename><surname>Sun</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Zayed University of Artificial Intelligence</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lingjing</forename><surname>Kong</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Guangyi</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Zayed University of Artificial Intelligence</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Loka</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Zayed University of Artificial Intelligence</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Gongxu</forename><surname>Luo</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Zayed University of Artificial Intelligence</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zijian</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yixuan</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Zayed University of Artificial Intelligence</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yujia</forename><surname>Zheng</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Zayed University of Artificial Intelligence</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mengyue</forename><surname>Yang</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">University of Bristol</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Petar</forename><surname>Stojanov</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Eran</forename><surname>Segal</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Zayed University of Artificial Intelligence</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Zayed University of Artificial Intelligence</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Zayed University of Artificial Intelligence</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">CAUSAL REPRESENTATION LEARNING FROM MULTI-MODAL BIOMEDICAL OBSERVATIONS</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E5088469E2B377F69F29BE7360545CB8</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-11-30T00:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Prevalent in biomedical applications (e.g., human phenotype research), multimodal datasets can provide valuable insights into the underlying physiological mechanisms. However, current machine learning (ML) models designed to analyze these datasets often lack interpretability and identifiability guarantees, which are essential for biomedical research. Recent advances in causal representation learning have shown promise in identifying interpretable latent causal variables with formal theoretical guarantees. Unfortunately, most current work on multimodal distributions either relies on restrictive parametric assumptions or yields only coarse identification results, limiting their applicability to biomedical research that favors a detailed understanding of the mechanisms. In this work, we aim to develop flexible identification conditions for multimodal data and principled methods to facilitate the understanding of biomedical datasets. Theoretically, we consider a nonparametric latent distribution (c.f., parametric assumptions in previous work) that allows for causal relationships across potentially different modalities. We establish identifiability guarantees for each latent component, extending the subspace identification results from previous work. Our key theoretical contribution is the structural sparsity of causal connections between modalities, which, as we will discuss, is natural for a large collection of biomedical systems. Empirically, we present a practical framework to instantiate our theoretical insights. We demonstrate the effectiveness of our approach through extensive experiments on both numerical and synthetic datasets. Results on a real-world human phenotype dataset are consistent with established biomedical research, validating our theoretical and methodological framework.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Multimodal datasets provide rich and comprehensive insights into complex biomedical systems, offering the potential to provide a deeper understanding of physiological mechanisms. For example, the human phenotype dataset <ref type="bibr" target="#b35">(Levine et al., 2024)</ref> contains measurements from multiple modalities, including anthropometric data, sleep monitoring, and genetic information. Proper analysis of such data can potentially uncover the underlying mechanisms that drive phenotypic diversity and disease susceptibility, leading to the discovery of novel molecular markers and the development of predictive models for disease. Recent advances in large-scale models have made it possible to exploit large biomedical datasets for various tasks such as protein structure prediction <ref type="bibr" target="#b26">(Jumper et al., 2021;</ref><ref type="bibr" target="#b40">Lin et al., 2023)</ref>, gene-disease association identification <ref type="bibr" target="#b13">(Diaz Gonzalez et al., 2023;</ref><ref type="bibr" target="#b79">Zagirova et al., 2023)</ref>, and novel drug candidate discovery <ref type="bibr" target="#b54">(Pal et al., 2023;</ref><ref type="bibr">Zheng et al., 2024b)</ref>.</p><p>Despite the impressive performance of these models, their trustworthiness remains a contentious issue <ref type="bibr">(Zheng et al., 2023)</ref>. A major concern lies in their lack of interpretability, which poses significant challenges in biomedical research and hinders the safe and ethical application of these models. For example, in clinical decision-making <ref type="bibr" target="#b19">(Hager et al., 2024)</ref>, if the model recommends a specific treatment plan for a patient, it is important for clinicians to understand the rationale behind the recommendation. Without such transparency, it is difficult to trust the model's output or integrate these systems into critical decision-making workflows. Although several explainable models have been developed for multimodal datasets <ref type="bibr" target="#b66">(Tang et al., 2023)</ref>, this area remains largely underexplored.</p><p>Fortunately, recent advances in causal representation learning (CRL) <ref type="bibr" target="#b60">(Schölkopf et al., 2021)</ref> have shown promise in identifying latent causal structures from raw observations, making it well-suited for biomedical applications. For example, a plethora of CRL studies <ref type="bibr" target="#b23">(Hyvarinen et al., 2019;</ref><ref type="bibr">Khemakhem et al., 2020a;</ref><ref type="bibr">Zhang et al., 2024b;</ref><ref type="bibr" target="#b6">Buchholz et al., 2024;</ref><ref type="bibr">von Kügelgen et al., 2023;</ref><ref type="bibr">Zhang et al., 2024a;</ref><ref type="bibr">Li et al., 2024c;</ref><ref type="bibr" target="#b1">Ahuja et al., 2023)</ref> effectively utilize temporal information or domain indices to identify latent causal models and apply them in fMRI data. Recently, a growing body of CRL research has investigated multimodal distributions <ref type="bibr" target="#b77">(Yao et al., 2023;</ref><ref type="bibr" target="#b47">Morioka &amp; Hyvarinen, 2023;</ref><ref type="bibr">2024;</ref><ref type="bibr" target="#b12">Daunhawer et al., 2023;</ref><ref type="bibr" target="#b65">Sturma et al., 2023;</ref><ref type="bibr" target="#b18">Gresele et al., 2020)</ref>. These works leverage shared information across modalities to establish identifiability guarantees for latent variables <ref type="bibr" target="#b77">(Yao et al., 2023;</ref><ref type="bibr" target="#b48">Morioka &amp; Hyvarinen, 2024;</ref><ref type="bibr" target="#b12">Daunhawer et al., 2023)</ref>. Despite these advancements, some aspects of these works are still limited. For instance, Von <ref type="bibr" target="#b70">Kügelgen et al. (2021)</ref>; <ref type="bibr" target="#b12">Daunhawer et al. (2023)</ref>; <ref type="bibr" target="#b77">Yao et al. (2023)</ref> only focus on identifying latent subspaces that are directly shared by multiple modalities. In practice, however, many informative latent variables may influence multiple modalities indirectly through intermediate latent mechanisms. Moreover, such subspace identifiability loses track of the intricate causal influences among individual components, leading to a limited view of the underlying latent mechanism. <ref type="bibr" target="#b48">Morioka &amp; Hyvarinen (2024)</ref>; <ref type="bibr" target="#b18">Gresele et al. (2020)</ref>; <ref type="bibr" target="#b47">Morioka &amp; Hyvarinen (2023)</ref> rely on specific assumptions about latent variable distributions (e.g., independence or exponential family). These constraints significantly limit their applicability for biomedical datasets that involve complex interactions among latent factors. In this work, we aim to develop identification theory with multimodal biomedical datasets in mind, and design principled and interpretable models to facilitate analyzing such datasets. We assume that observations x (m) in each modality m are generated by a specific set of latent components {z for m ̸ = n, i ̸ = j, as shown in Figure <ref type="figure" target="#fig_0">1</ref>. Theoretically, we provide identifiability guarantees for each latent component z (m) i , thus generalizing the subspace identification results in <ref type="bibr" target="#b77">Yao et al. (2023)</ref>; <ref type="bibr" target="#b12">Daunhawer et al. (2023)</ref> while avoiding independence or parametric restrictions on the latent distribution p({z (m) } m ) as in <ref type="bibr" target="#b47">Morioka &amp; Hyvarinen (2023;</ref><ref type="bibr">2024)</ref>; <ref type="bibr" target="#b18">Gresele et al. (2020)</ref>. In particular, we first show that any latent subspace z (m) can be identified as long as z (m) exerts sufficient influences on other modalities, which is weaker than assuming that z (m) is directly shared across multiple modalities as in <ref type="bibr" target="#b12">Daunhawer et al. (2023)</ref>; <ref type="bibr" target="#b77">Yao et al. (2023)</ref>. Based on this subspace identification, we leverage the sparsity of the causal connections between modalities to further identify each latent component {z (m) i } i . This notion of causal sparsity has been explored in recent work <ref type="bibr" target="#b32">(Lachapelle et al., 2023;</ref><ref type="bibr" target="#b75">Xu et al., 2024;</ref><ref type="bibr" target="#b87">Zheng et al., 2022)</ref> in other causal identification settings and has been shown realistic in many biomedical systems <ref type="bibr" target="#b7">(Busiello et al., 2017;</ref><ref type="bibr" target="#b45">Milo et al., 2002;</ref><ref type="bibr" target="#b3">Babu et al., 2004;</ref><ref type="bibr" target="#b73">West et al., 2002;</ref><ref type="bibr" target="#b4">Banavar et al., 1999)</ref>, as we will discuss further in Section 4.</p><p>Empirically, we develop a theoretically grounded estimation framework to recover the latent components in each modality. Our model implements our theoretical conditions (in particular, conditional independence and sparsity constraints) on top of normalizing flow <ref type="bibr" target="#b21">(Huang et al., 2018;</ref><ref type="bibr" target="#b30">Kobyzev et al., 2020)</ref> within the encoder-decoder framework. Extensive experiments on both numerical and synthetic datasets demonstrate its effectiveness. Most notably, our framework enables the identification of latent causal variables that capture complex biomedical interactions and facilitates the analysis of potential causal mechanisms across modalities, which are important for clinical decision-making. The evaluation results on a real-world human phenotype dataset provide novel insights into the relationships between modalities, and the discovered causal relationships align with the findings from biomedical research, highlighting our contributions to the biomedical domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>ML models for biomedical research. For biomedical applications, ML models are developed to extract informative representations to facilitate downstream tasks, including DNA sequence modeling <ref type="bibr" target="#b89">(Zhou et al., 2024;</ref><ref type="bibr" target="#b50">Nguyen et al., 2023;</ref><ref type="bibr">Dalla-Torre et al., 2023)</ref>, protein structure prediction <ref type="bibr" target="#b26">(Jumper et al., 2021;</ref><ref type="bibr" target="#b40">Lin et al., 2023)</ref>, and disease detection <ref type="bibr" target="#b88">(Zhou et al., 2023;</ref><ref type="bibr" target="#b24">Jang et al., 2024)</ref>. The success of large language models (LLMs) has significantly advanced sequence modeling for DNA, RNA, and proteins <ref type="bibr" target="#b8">(Celaj et al., 2023;</ref><ref type="bibr" target="#b62">Shulgina et al., 2024;</ref><ref type="bibr" target="#b51">Nguyen et al., 2024;</ref><ref type="bibr" target="#b38">Li et al., 2023;</ref><ref type="bibr" target="#b9">Chen et al., 2023;</ref><ref type="bibr" target="#b40">Lin et al., 2023)</ref>, yet these methods primarily operate on a single modality, limiting their applicability to the multimodal datasets, which are commonly encountered in biomedical research. Although several studies have explored integrating multimodal biomedical data <ref type="bibr" target="#b17">(Garau-Luis et al., 2024;</ref><ref type="bibr" target="#b55">Pei et al., 2024;</ref><ref type="bibr" target="#b67">Taylor et al., 2022)</ref>, these approaches often lack theoretical guarantees, raising concerns about the reliability of their results. In this paper, we leverage causal principles to develop theoretically sound ML models for multimodal biomedical data, aiming to provide reliable and interpretable insights into complex biomedical systems.</p><p>Multimodal representation learning. Multimodal representation learning <ref type="bibr" target="#b80">(Zhang et al., 2020;</ref><ref type="bibr" target="#b43">Manzoor et al., 2023)</ref> refers to the process of learning representations from multiple data modalities (e.g., text, image, audio) for specific tasks. Recent advances have leveraged contrastive learning techniques to improve the alignment of latent spaces across different modalities <ref type="bibr" target="#b12">(Daunhawer et al., 2023;</ref><ref type="bibr" target="#b72">Wang et al., 2022;</ref><ref type="bibr" target="#b58">Radford et al., 2021;</ref><ref type="bibr" target="#b29">Khosla et al., 2020)</ref>. Methods like CLIP <ref type="bibr" target="#b58">(Radford et al., 2021)</ref> and Contrastive Predictive Coding <ref type="bibr" target="#b53">(Oord et al., 2018)</ref> have demonstrated the ability to recover shared latent factors across modalities by (implicitly) maximizing mutual information between representations. However, challenges remain in achieving finding modality-specific representations, which requires novel approaches that preserve the unique characteristics of each modality.</p><p>Identifiable CRL. CRL aims to identify high-level causal variables from low-level observations, integrating principles from both machine learning and causality <ref type="bibr" target="#b60">(Schölkopf et al., 2021)</ref>, and can be viewed as an extension of causal discovery <ref type="bibr" target="#b64">(Spirtes et al., 2001;</ref><ref type="bibr">Li et al., 2024a;</ref><ref type="bibr" target="#b42">Luo et al., 2025;</ref><ref type="bibr">Li et al., 2024b;</ref><ref type="bibr" target="#b91">Ziu et al., 2024)</ref>. CRL methods with identifiability guarantees can be classified based on the assumptions they impose, including sparsity constraints <ref type="bibr" target="#b75">(Xu et al., 2024;</ref><ref type="bibr" target="#b87">Zheng et al., 2022;</ref><ref type="bibr">Zheng &amp; Zhang, 2023;</ref><ref type="bibr" target="#b33">Lachapelle et al., 2024)</ref>, interventional/multi-distribution settings <ref type="bibr" target="#b23">(Hyvarinen et al., 2019;</ref><ref type="bibr">Khemakhem et al., 2020a;</ref><ref type="bibr">Zhang et al., 2024b;</ref><ref type="bibr" target="#b31">Kong et al., 2023;</ref><ref type="bibr" target="#b6">Buchholz et al., 2024;</ref><ref type="bibr">von Kügelgen et al., 2023;</ref><ref type="bibr">Zhang et al., 2024a;</ref><ref type="bibr">Li et al., 2024c;</ref><ref type="bibr" target="#b69">Varici et al., 2023;</ref><ref type="bibr" target="#b1">Ahuja et al., 2023;</ref><ref type="bibr" target="#b25">Jiang &amp; Aragam, 2023)</ref>, and of particular relevance to our work, multimodality <ref type="bibr" target="#b77">(Yao et al., 2023;</ref><ref type="bibr" target="#b47">Morioka &amp; Hyvarinen, 2023;</ref><ref type="bibr">2024;</ref><ref type="bibr" target="#b12">Daunhawer et al., 2023;</ref><ref type="bibr" target="#b65">Sturma et al., 2023;</ref><ref type="bibr" target="#b18">Gresele et al., 2020)</ref>. To provide a clearer comparison, Table <ref type="table" target="#tab_0">1</ref> summarizes representative works in the multimodality category and highlights their differences from our work.</p><p>Empirical CRL for multimodal applications. In contrast to the previously discussed works that emphasize identifiability, another line of multimodal CRL research prioritizes practical applications in various domains, without addressing theoretical identifiability. <ref type="bibr" target="#b44">Mao et al. (2022)</ref> assume independent latent variables and introduce a two-module amortized variational algorithm to learn representations from medical images and biomedical data. <ref type="bibr">Zheng et al. (2024a)</ref> develop a contrastive learning-based approach to extract modality-specific and modality-invariant representations from time-series tabular and textual data for root cause analysis. <ref type="bibr" target="#b59">Rawls et al. (2021)</ref> leverage behavioral and psychiatric phenotyping alongside high-resolution neuroimaging data from the Human Connectome Project <ref type="bibr" target="#b68">(Van Essen et al., 2013)</ref>, and perform greedy fast causal inference <ref type="bibr" target="#b52">(Ogarrio et al., 2016)</ref> to investigate causal relations in alcohol use disorder. In contrast, our work establishes formal identification theory and integrates the theoretical insights into our estimation model. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">LATENT MULTIMODAL CAUSAL MODELS</head><p>Real-world biomedical datasets often integrate multiple modalities, each characterizing a unique yet interrelated aspect of the subject. For instance, the human phenotype dataset <ref type="bibr" target="#b61">(Shilo et al., 2021)</ref> consists of tabular data, time series, images, and text, capturing diverse biomedical measurements such as anthropometrics, sleep monitoring, and genetic information. Understanding the latent factors behind each modality and their interplay can provide valuable insights into underlying biomedical mechanisms, ultimately facilitating the advancement of biomedical technologies. With this goal in mind, we formalize the multimodal data-generating processes as follows.</p><p>x</p><formula xml:id="formula_0">(1) x (2) x (3) η (1) η (2) η (3) z (1) 1</formula><p>Figure <ref type="figure">2</ref>: An illustrative example of the hypothesis space underlying the biomedical system.</p><p>Data-generating processes. Let x := [x (<ref type="foot" target="#foot_0">1</ref>) , . . . , x (M ) ] be a set of observations/measurements from M modalities, where x (m) ∈ R d(x (m) ) represents the observation from modality m with dimensionality d(x (m) ). Let z = [z (1) , . . . , z (M ) ] be the set of causally related latent variables underlying M modalities. Specifically, the data generation process (Figure <ref type="figure">2</ref>) can be formulated as</p><formula xml:id="formula_1">z (m) i := g z (m) i (Pa(z (m) i ), ϵ<label>(m) i</label></formula><p>), (latent causal relations)</p><p>(1)</p><formula xml:id="formula_2">x (m) := g x (m) (z (m) , η (m) ), (<label>generating functions) (2)</label></formula><p>where Pa(•) denotes the parents of a variable. Since we allow for causal relations to exist within and across modalities, Pa(•) potentially includes latent variables across multiple modalities. The differentiable function g z encodes the latent causal graph connecting the latent components, and its Jacobian matrix J gz can be permuted into a strictly triangular matrix. We denote ϵ (m) i</p><p>as the exogenous variable for z</p><formula xml:id="formula_3">(m) i</formula><p>, where all exogenous variables are mutually independent. η (m) represents domain-specific information independent of other components.</p><p>Example. In healthcare, different modalities capture complementary physiological aspects. A chest X-ray x (m) may reflect latent factors such as lung density, cardiac silhouette, and ribcage structure, represented by z (m) . These latent factors can causally influence those in other modalities, z (n) , such as pulmonary function parameters (e.g., forced vital capacity) and cardiovascular biomarkers (e.g., left ventricular mass). These, in turn, may affect electrical activity recorded in an ECG, represented by x (n) , by modulating heart rate variability and conduction patterns.</p><p>Goal. As outlined previously, we aim to learn the latent variables underlying each modality and their causal relations. Formally, consider two specifications of the data-generating process in Eq. (1) and Eq. ( <ref type="formula" target="#formula_2">2</ref>): θ := {g x (m) , g z (m) , p(ϵ (m) )} M m=1 and θ := {ĝ x (m) , ĝz (m) , p(ϵ (m) )} M m=1 , both of which fit the marginal distribution p(x). Our objective is to show that, given the same value of x, each estimated latent component ẑ(m)</p><formula xml:id="formula_4">i is equivalent to its true counterpart z (m) i up to an invertible trans- formation h (m) i , i.e., ẑ<label>(m)</label></formula><formula xml:id="formula_5">i = h (m) i (z (m) i</formula><p>). 1 This component-wise identifiability ensures that latent components (e.g., gene types, nutrient levels) are disentangled from the observed measurements x while preserving their original information. Once component-wise identifiability is achieved, one can readily apply standard causal discovery algorithms (e.g., PC <ref type="bibr" target="#b64">(Spirtes et al., 2001)</ref>) to the identified components ẑ(m) i to infer the graphical structures. The choice of structure learning algorithms can be tailored to the assumed graph class (e.g., potentially non-DAGs), and this step is orthogonal to our contribution. These structures characterize the interactions between all latent components across modalities, which is particularly desirable for biomedical applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">IDENTIFICATION THEORY</head><p>As motivated in Section 3, we address the component-wise identifiability of latent components z (m) i .</p><p>Remarks on the problem. Identification for multimodal distributions often leverages the structure among the available modalities. However, component-wise identification, especially in the general nonparametric setting, is challenging. <ref type="bibr" target="#b12">Daunhawer et al. (2023);</ref><ref type="bibr" target="#b70">Von Kügelgen et al. (2021)</ref>; <ref type="bibr" target="#b77">Yao et al. (2023)</ref> require certain information redundancy: the information of the latent variables should be fully shared and preserved by the observations of at least two modalities -that is, we can express z (m) as functions of x (m1) and x (m2) individually. Moreover, the identification can only be achieved up to subspaces (i.e., groups of latent components) determined by the sharing pattern. Often, however, the latent components may not be fully shared by multiple modalities. For example, in health monitoring, while sleep monitoring data (e.g., sleep stages or duration) may not fully encode genetic predispositions, genetic factors may still influence sleep disorders, such as insomnia and circadian rhythm disruptions. In this case, the subspace identification may fall short of providing detailed interpretations of biomedical systems and the mechanisms encoded in the graphical structures over individual causal components.</p><p>For work that achieves component-wise identifiability, <ref type="bibr" target="#b47">Morioka &amp; Hyvarinen (2023;</ref><ref type="bibr">2024)</ref> assume that the latent distribution p({z (m) } M m=1 ) follows an exponential family form with additive causal influences from multiple parents, which may be restrictive in general cases. For instance, in brain imaging studies, fMRI data and EEG data capture different neural activities, and the interactions between brain regions are often highly nonlinear. Clearly, for general multimodal distributions (Figure <ref type="figure">2</ref>), we cannot access the information redundancy assumed in <ref type="bibr" target="#b12">Daunhawer et al. (2023);</ref><ref type="bibr" target="#b70">Von Kügelgen et al. (2021)</ref>; <ref type="bibr" target="#b77">Yao et al. (2023)</ref> and the nicely-behaved latent causal models in parametric assumptions <ref type="bibr" target="#b47">(Morioka &amp; Hyvarinen, 2023;</ref><ref type="bibr">2024)</ref>.</p><p>Our high-level approach. We divide the problem into two parts: we first identify latent subspaces z (m) (Section 4.1) and further disentangle identified subspaces into components z (m) i (Section 4.2). For the subspace identification, we only assume that the information of the subspace z (m) is preserved in its corresponding observation x (m) and exerts sufficient influence on other modalities' observations x (-m) , thus weakening the redundancy assumption in previous work <ref type="bibr" target="#b12">(Daunhawer et al., 2023;</ref><ref type="bibr" target="#b77">Yao et al., 2023)</ref>. For the component-wise identification, we leverage a natural notion of structural sparsity in the literature <ref type="bibr" target="#b87">(Zheng et al., 2022;</ref><ref type="bibr" target="#b33">Lachapelle et al., 2024)</ref> -the dependency among all the modalities should be explained with a minimal number of causal edges among latent subspaces {z (m) } M m=1 . This allows us to further disentangle each subspace into components, without resorting to parametric assumptions <ref type="bibr" target="#b47">(Morioka &amp; Hyvarinen, 2023;</ref><ref type="bibr">2024)</ref>.</p><p>Notations. We denote the dimensionality and the component indices of a given argument with d(•) and I(•), respectively. The notation -m represents the complement of modality m, while superscripts and subscripts enclosed in parentheses, such as (m), explicitly index modality m. We denote sub-matrices using the notation [•] R,C , where R and C are index sets corresponding to row and column selections, respectively. In this notation, setting R (or C) to : indicates the inclusion of all indices along the corresponding dimension.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">IDENTIFYING LATENT SUBSPACES</head><p>As previously discussed, we now provide the subspace identifiability. Formally, we would like to show that the estimated latent subspace ẑ(m) for any modality m and its true counterpart z (m) are equivalent up to an invertible map h (m) (•), i.e., ẑ(m) = h (m) (z (m) ).</p><p>Given the data-generating process Eq. ( <ref type="formula" target="#formula_2">2</ref>), the task is to remove modality-specific information η (m) from the observational data x (m) while retaining the latent variables z (m) causally related to other modalities. In light of this, we express the relations between the latent variables z (m) and the observation of its own modality x (m) and other modalities x (-m) as Eq. (3).</p><formula xml:id="formula_6">x (m) = g x (m) (z (m) , η (m) ), x (-m) = gx (-m) (z (m) , η(-m) ),<label>(3)</label></formula><p>where η(-m) denotes all the information necessary to generate the complement group x (-m) beyond z (m) .<ref type="foot" target="#foot_1">2</ref> Consequently, η(-m) may admit causal/statistical relations with z (m) . We denote the joint map of g x (m) and gx (-m) as g(m) : (z (m) , η (m) , η(-m) ) → x. A2 [Linear Independence]: The generating function gx (-m) is smooth and its Jacobian columns corresponding to z (m) (i.e., [J gx <ref type="bibr">(-m)</ref> ] :,I(z (m) ) ) are linearly independent almost anywhere.</p><p>Discussion on the conditions. Condition 4.1-A1 requires that the information of the latent variables z (m) is preserved in its observation x (m) , so that the identification of latent variables is welldefined <ref type="bibr" target="#b23">(Hyvarinen et al., 2019;</ref><ref type="bibr">Khemakhem et al., 2020a;</ref><ref type="bibr" target="#b70">Von Kügelgen et al., 2021;</ref><ref type="bibr" target="#b31">Kong et al., 2023;</ref><ref type="bibr" target="#b77">Yao et al., 2023;</ref><ref type="bibr" target="#b12">Daunhawer et al., 2023)</ref>. Since this holds for any modality m, the observations x (-m) should collectively preserve the information of other modalities z (-m) .</p><p>Condition 4.1-A2 formalizes the notation of a minimal connectivity over modalities: z (m) should also exert sufficient influence on other modalities z (-m) , so that the other modality observations x (-m) could be informative to identify z (m) . This condition excludes degenerate scenarios where the causal influences between modalities are nearly negligible and is equivalent to local invertibility of z (m) , which is strictly weaker than the global invertibility assumption in previous work <ref type="bibr" target="#b12">(Daunhawer et al., 2023;</ref><ref type="bibr" target="#b70">Von Kügelgen et al., 2021;</ref><ref type="bibr" target="#b77">Yao et al., 2023</ref>) (e.g., y = x 2 is locally invertible but not globally so), as discussed earlier.</p><p>Theorem 4.2 (Subspace Identifiability).</p><formula xml:id="formula_7">Let θ := {g x (m) , gz (-m) , p(ϵ (m) ), p(ε (-m) )} M m=1 and θ := {ĝ x (m) , ĝz (-m) , p(ε (m) ), p( ε(-m) )} M</formula><p>m=1 be two specifications of the data-generating process in Eq. (3). Suppose that they generate identical observational distributions (i.e., p(x) = p(x)), θ satisfies Condition 4.1, and θ satisfies Condition 4.1-A1. The latent subspace ẑ(m) for any group m and its counterpart z (m) are equivalent up to an invertible map h</p><formula xml:id="formula_8">(m) (•), i.e., ẑ(m) = h (m) (z (m) ).</formula><p>Interpretation and proof sketch. Theorem 4.2 states that one can disentangle the modalityspecific information η (m) and the latent variables z (m) contained in the observation x (m) (which is a mixture of both). To achieve this, we leverage the fact that η (m) has no influence on other modalities x (-m) , while z (m) has a non-trivial influence on x (-m) , as characterized in Condition 4.1-A2. This crucial distinction provides sufficient footprints to disentangle these two subspaces for each modality, yielding the intended result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">IDENTIFYING LATENT COMPONENTS</head><p>Proceeding from the subspace identifiability (Theorem 4.2), we now further disentangle each subspace into individual components z (m) i as outlined in Section 3. As foreshadowed, our key condition entails the sparsity of the graphical structures between modalities. Such dependency structures are captured in the generating function g z defined component-wise in Eq. ( <ref type="formula" target="#formula_13">1</ref>), in particular its partial derivatives. We now introduce Condition 4.3, which facilitates component-wise identification. Additional notations. We denote the indices of the non-zero matrix entries by Supp(•). We denote the collection of partial derivatives among all latent components z) . We adopt diag(•) to denote matrices consisting of equally-sized square matrices on its diagonal and define T to possess the structure</p><formula xml:id="formula_9">∂z (m) i ∂z (n) j as a matrix func- tion G(z, ϵ) ∈ R d(z)×d(</formula><formula xml:id="formula_10">T = diag(T 1 , . . . , T M ) with invertible T m ∈ R d(z (m) )×d(z (m) )</formula><p>. We denote the class of generalized permutation matrices of dimensionality d(z) as P(d(z)).</p><p>Condition 4.3 (Component Identifiability Conditions). Over the domain of (z, ϵ), for any modality m and any T ̸ ∈ P(d(z)), we have (when component-wise identification breaks down), the cross-modality causal connections in G are guaranteed to be denser than those in Ĝ. We give a simple example to aid intuition in Figure <ref type="figure" target="#fig_3">3</ref>: for a causal graph with three modalities, z</p><formula xml:id="formula_11">m̸ =n∈[M ] T -1 m [G] (m),(n) T n 0 &gt; m̸ =n∈[M ] [G] (m),(n) 0 . (4)</formula><p>(1)</p><formula xml:id="formula_12">1 → z (2) 1 → z (3) 1 and z (1) 2 → z (2) 2 → z (3) 2 , suppose that ẑ(2) 1 is a non-trivial mixture of z (2)</formula><p>1 and z</p><p>(2)</p><p>2 and other components are correctly identified, i.e., [ẑ</p><formula xml:id="formula_13">(1) 1 , ẑ(1) 2 , ẑ(2) 1 , ẑ(2) 2 , ẑ(3) 1 , ẑ(3) 2 ] = [z (1) 1 , z<label>(1)</label></formula><p>2 , h(z</p><formula xml:id="formula_14">(2) 1 , z<label>(2)</label></formula><p>2 ), z</p><p>2 , z</p><formula xml:id="formula_16">(3) 1 , z<label>(3)</label></formula><p>2 ]. As a consequence, the alternative causal graph Ĝ would include additional edges ẑ(1)</p><formula xml:id="formula_17">2 → ẑ(2) 1 and ẑ(2) 2 → ẑ(3)</formula><p>1 , giving rise to a strictly denser graph. In Theorem 4.4, we show that this sparse structure could give us the desired component-wise identifiability under a proper sparse regularization constraint. The availability of multiple modalities greatly improves the feasibility of such sparsity conditions, especially with a large number of modalities, because the entanglement is limited within a single modality (owing to Theorem 4.1) and all other modalities can be leveraged to provide space for sparse connections.</p><p>Sparsity conditions have been embraced by the causal representation learning community <ref type="bibr" target="#b33">(Lachapelle et al., 2024;</ref><ref type="bibr" target="#b46">Moran et al., 2022;</ref><ref type="bibr" target="#b16">Fumero et al., 2023;</ref><ref type="bibr" target="#b75">Xu et al., 2024)</ref>. Especially relevant to our work is <ref type="bibr" target="#b87">Zheng et al. (2022)</ref>. As discussed above, we are obliged to deal with causal structures among all latent variables. In contrast, <ref type="bibr" target="#b87">Zheng et al. (2022)</ref> assumes the sparsity of the causal connections between the latent variables and the observed variables -the directions (from the latent to the observed variables) are given and the children are directly observed. Notably, sparse properties manifest in biomedical systems of our interest, including gene regulatory networks <ref type="bibr" target="#b45">(Milo et al., 2002;</ref><ref type="bibr" target="#b3">Babu et al., 2004;</ref><ref type="bibr" target="#b49">Nacher &amp; Akutsu, 2013;</ref><ref type="bibr" target="#b41">Liu et al., 2011)</ref>, metabolic systems <ref type="bibr" target="#b73">(West et al., 2002;</ref><ref type="bibr" target="#b4">Banavar et al., 1999)</ref>, and other living systems <ref type="bibr" target="#b7">(Busiello et al., 2017)</ref>, evidencing the plausibility of Condition 4.3 for biomedical applications.</p><formula xml:id="formula_18">Theorem 4.4 (Component-wise Identifiability). Let θ := ({g x (m) , g z (m) , p(ϵ (m) )} M m=1</formula><p>) and θ := ({ĝ x (m) , ĝz (m) , p(ϵ (m) )} M m=1 ) be two specifications of the data-generating process in Eq. (1) and Eq. (2). Suppose that they generate identical observational distributions (i.e., p(x) = p(x)) and θ satisfies Condition 4.1 and Condition 4.3. If θ satisfies the following sparse regularization condition:</p><formula xml:id="formula_19">m̸ =n∈[M ] [ Ĝ] (m),(n) 0 ≤ m̸ =n∈[M ] [G] (m),(n) 0 ,<label>(5)</label></formula><formula xml:id="formula_20">each component z (m) i and its counterpart ẑ(m) π(i) are equivalent up to an invertible map h(•), i.e., ẑ(m) π(i) = h(z (m) i ) under a permutation π over [d(z (m) )].</formula><p>Interpretation and proof sketch. The key idea of Theorem 4.4 is that for sparse causal graphs (as characterized in Condition 4.3), the mixing of latent components in any modality would introduce unnecessary causal edges connecting the other modalities. As the sparsity regularization Eq. ( <ref type="formula" target="#formula_19">5</ref>) selects alternative models θ that are not denser than the model θ, the mixing within each modality would be excluded. Consequently, each latent component</p><formula xml:id="formula_21">ẑ(m) i is a function of a unique component z (m) j</formula><p>, yielding the desired component-wise identifiability.</p><p>Implications. In the context of biomedical applications, Theorem 4.4 indicates that under appropriate constraints, each component ẑ(m) i in our estimation uniquely captures the information of an intrinsic biomedical factor behind the medical measurements (e.g., genetic predisposition). Therefore, the learned representation enjoys strong interpretability under theoretical guarantees, which is often lacking in existing biomedical models, as noted in Section 2. Theorem 4.2 and Theorem 4.4 provide insights for practical model design, which we employ in our architecture in Section 5. Shared latent variables. Certain applications may involve latent variables that are shared across modalities. In such scenarios, we can employ contrastive learning objectives and the associated theoretical guarantees in previous work <ref type="bibr" target="#b77">(Yao et al., 2023;</ref><ref type="bibr" target="#b12">Daunhawer et al., 2023;</ref><ref type="bibr" target="#b70">Von Kügelgen et al., 2021)</ref> as a pre-processing procedure and treat such shared latent variables as separate modalities in our implementation. Please refer to Appendix C.3, C.4, and E for detailed discussion and results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">ESTIMATION MODEL ARCHITECTURES</head><p>Given the identifiability results, we further propose an estimation framework (shown in Figure <ref type="figure" target="#fig_4">4</ref>) that enforces the proposed assumptions as constraints to identify the latent variables in each modality. The observations are then reconstructed with corresponding decoders as x(m) . We enforce independence conditions by minimizing the KL divergence term</p><formula xml:id="formula_22">D KL [{η (m) } M m=1 , {ε i } d(z)</formula><p>i=1 ]||N (0, I) . We enforce the sparsity constraint by minimizing the L 1 norm in the inferred adjacency matrix Â.</p><p>Encoder and decoder. Each modality x (m) is given as an input to the corresponding encoder and outputs the estimated latent ẑ(m) and domain-specific information η(m) . They are then concatenated and passed to the corresponding decoder to reconstruct the observations as x(m) . The reconstruction loss is calculated using the mean squared error (MSE) as</p><formula xml:id="formula_23">L Recon = M m=1 ||x (m) -x(m) || 2 2 .</formula><p>Conditional independence constraints. Given Eq (3), we enforce the conditional independence condition</p><formula xml:id="formula_24">x (m) ⊥ ⊥ x (n) | z (m) and the independence condition on η (m) ⊥ ⊥ z (m) by enforcing inde- pendence among components in γ = [{η (m) } M m=1 , {ε i } d(z) i=1</formula><p>]. Such equivalence is shown in Propositions 5.1 and 5.2, and proofs are provided in Appendix B. Specifically, we minimize the KL divergence loss between the posterior and a Gaussian prior distribution:</p><formula xml:id="formula_25">L Ind = D KL (p(γ)||N (0, I)).</formula><p>Proposition 5.1. [Conditional Independence Condition] Let x (m) and x (n) be two different multimodal observations. z (m) ⊂ z are the set of block-identifying latent variables, and η (m) ⊂ η are domain-specific information in modality m. We have</p><formula xml:id="formula_26">x (m) ⊥ ⊥ x (n) | z (m) ⇐⇒ η (m) ⊥ ⊥ η (n) .</formula><p>Proposition 5.2. [Independent Noise Condition] Let z and η be the block-identified latent variables and domain-specific information, respectively, across all modalities. Denote ϵ as the exogenous variables in the latent causal structure. We have η ⊥ ⊥ z ⇐⇒ η ⊥ ⊥ ϵ.</p><p>Sparsity regularization. We use flow to estimate the exogenous variables ϵ in Eq. ( <ref type="formula" target="#formula_13">1</ref>) and implement the causal relations through a learnable adjacency matrix Â. The binary values in Â represent the causal generation process between latent variables, e.g. Âi,j = 1 indicates ẑj is the parent of ẑi , while Âi,j = 0 means ẑj dose not contribute to the generation of ẑi . For each component ẑi , we select its parents Pa(ẑ i ) based on the adjacency matrix, and apply the flow transformation to get εi .</p><p>To encourage sparsity among the latent variables ẑ, we impose a regularization term on the learned adjacency matrix. Based on the sparsity assumption, the optimal causal graph should be the minimal one that still allows the model to accurately match the ground truth generative distribution. To achieve this, we reduce the dependencies between different components of ẑ by adding a L 1 penalty on the adjacency matrix, s.t., L Sp = || Â|| 1 .</p><p>Optimization. The model parameters are optimized using the combination objective:</p><formula xml:id="formula_27">L = α Recon L Recon + α Ind L Ind + α Sp L Sp . (6)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">EXPERIMENT RESULTS</head><p>To evaluate the efficacy of our proposed method, we conduct extensive experiments on (1) numerical, (2) synthetic and (3) real-world datasets. In terms of the baselines, we compare our method with: (1) BetaVAE <ref type="bibr" target="#b20">(Higgins et al., 2017)</ref>, which does not consider causal relations in the latent space.</p><p>(2) CausalVAE <ref type="bibr" target="#b76">(Yang et al., 2020)</ref>, which considers the causally related latent variables with  Results and ablation. Figure <ref type="figure" target="#fig_6">5</ref> shows the identifiability results in different cases, where the high MCC indicates the successful recovery of the latent variables. The inter-modal causal relations are successfully recovered (SHD=0) and the causal comparison result in case 1 is shown in Figure <ref type="figure" target="#fig_6">5</ref>(a). The identifiability comparison results are shown in Figure <ref type="figure" target="#fig_6">5</ref>(b) (MCL is not applicable in case 3 due to the two-modality constraint). CausalVAE requires additional supervision signals to establish identifiability, and MCL assumes content invariance and can only block-identify latent variables. In general, these baselines neither account for the multimodal setting nor the modality-specific latent variables, and therefore do not recover the latent variables.</p><p>As an ablation study, we further show the consequences of violating the sparsity assumptions to validate our theorem. Based on case 2, we create four types of datasets with different sparsity ratios and report the MCC in each scenario in Figure <ref type="figure" target="#fig_6">5(c</ref>). The sparsity ratio represents the ratio of existing causal links to all possible causal links between modality-specific latent variables. A value of 0 indicates that the latent variables between modalities are fully connected, while higher values correspond to sparser connections. The result shows that identifiability can be better achieved with a higher sparsity ratio, and our framework outperforms other baselines in all scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">SYNTHETIC DATASET: VARIANT MNIST</head><p>Setup. We manually create a variant of the MNIST dataset to encode causal relationships between different modalities, using colored MNIST <ref type="bibr" target="#b2">(Arjovsky et al., 2019)</ref> and fashion MNIST <ref type="bibr" target="#b74">(Xiao et al., 2017)</ref> as two different modalities. In colored MNIST, the horizontal position of the digit influences the image transparency. This horizontal position further serves as a causal factor for the vertical position of the fashion items in the fashion MNIST, which influences image grayscale. This design ensures a structured causal dependency across modalities while maintaining a non-deterministic mapping. Further data descriptions are provided in the Appendix D.2.   underlying each modality. We applied the PC algorithm <ref type="bibr" target="#b64">(Spirtes et al., 2001)</ref> to discover causal relationships between the estimated latent variables and other four additional tabular modalities (A, B, C, D), providing an implicit evaluation on the effectiveness. The result with direct causal relations is shown in Figure <ref type="figure" target="#fig_8">6</ref>, where variables from the same modality have the same color and different modalities have different colors.</p><p>A key finding is that the discovered causal relationships are consistent with findings from medical research. For example, Sleep 1 shows a direct causal relationship with Oxygen saturation, suggesting that sleep conditions may influence blood oxygen levels. This observation is consistent with previous studies <ref type="bibr" target="#b71">(Wali et al., 2020)</ref>. In addition, the fundus-related latent variables FRight 1 and FLeft 1 have a direct causal relationship with Age, suggesting that aging plays an important role in changes in retinal health <ref type="bibr" target="#b14">(Ege et al., 2002;</ref><ref type="bibr" target="#b15">Einbock et al., 2005)</ref>. Interestingly, the fundus image of the right eye has a direct causal relationship with the grip strength of the left hand, as recently demonstrated in biomedical research <ref type="bibr" target="#b5">(Bikbov et al., 2023;</ref><ref type="bibr" target="#b57">Qiu et al., 2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION AND LIMITATIONS</head><p>In this work, we develop a theoretically grounded framework for recovering latent causal variables from multi-modal observations. Extensive experimental results on synthetic and real-world datasets demonstrate the practical effectiveness of our approach. Limitations: Empirically, our framework assumes prior knowledge of the number of latent variables in each modality, which may be unrealistic in real-world scenarios. Additionally, a detailed evaluation against the quantitative benchmarks used in biomedical models remains an area for future exploration. Observation/measurement in each modality z (m)  Causally related latent variables in each modality x (m) , x (-m)  One specific observation in modality m, and the rest of others z (m) , z (-m)  One Notions of identifiability. Following the literature on ICA <ref type="bibr" target="#b22">(Hyvarinen &amp; Morioka, 2016;</ref><ref type="bibr" target="#b23">Hyvarinen et al., 2019;</ref><ref type="bibr" target="#b10">Comon, 1994)</ref> and causal representation learning <ref type="bibr" target="#b77">(Yao et al., 2023;</ref><ref type="bibr" target="#b70">Von Kügelgen et al., 2021;</ref><ref type="bibr" target="#b12">Daunhawer et al., 2023)</ref>, we assume that the generating function g x (m) (Eq. ( <ref type="formula" target="#formula_2">2</ref>)) is an invertible map from (z (m) , η (m) ) to x (m) (Condition 4.1). Under this invertibility assumption, given the value of x (m) , one can perfectly determine the value of z (m) , which is essentially the posterior p(z|x) (a point mass here). Here, z (m) is a function of x (m) , and the identifiability of g gives rise to the result that z (m) values can be identified from x (m) .</p><p>In statistics, to show identifiability, we start with equal distributions p ϕ1 = p ϕ2 to derive the equivalence of the parameters ϕ 1 = ϕ 2 . In our case, since the functions g x (m) , ĝx (m) are invertible, one can reason about the relation between the two specifications g x (m) and ĝx (m) through a composition h := ĝ-1</p><formula xml:id="formula_28">x (m) • g x (m) .</formula><p>For instance, h is the identity when the two specifications are identical. Similarly, in this work, we start with equal values of x to establish the relation between z and ẑ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B CONSTRAINTS IN THE ESTIMATION FRAMEWORK</head><p>Here we provide the proofs for the constraints utilized in the estimation framework.</p><p>Proposition B.1. [Conditional Independence Condition] Let x (m) and x (n) be two different multimodal observations. z (m) ⊂ z are the set of block-identifying latent variables, and η (m) ⊂ η are domain-specific information in modality m. We have</p><formula xml:id="formula_29">x (m) ⊥ ⊥ x (n) | z (m) ⇐⇒ η (m) ⊥ ⊥ η (n) . (<label>7</label></formula><formula xml:id="formula_30">)</formula><p>Proof. Given the data generation process in Eq. ( <ref type="formula" target="#formula_2">2</ref>), the following assumptions hold true for any m, n</p><formula xml:id="formula_31">∈ [M ]: (1) z (m) ⊥ ⊥ η (m) ; (2) z (m) ⊥ ⊥ η (n) ; (3) η (m) ⊥ ⊥ x (n) .</formula><p>Sufficient condition. Given LHS of Eq. ( <ref type="formula" target="#formula_29">7</ref>), we have</p><formula xml:id="formula_32">p(x (m) , x (n) | z (m) ) = p(x (m) | z (m) )p(x (n) | z (m) ). RHS ===⇒ p(x (m) , x (n) | z (m) ) = p(x (m) , x (n) , z (m) ) p(z (m) ) = p(η (m) , η (n) , z (m) ) p(z (m) ) |det ∂η (m) ∂x (m) ||det ∂η (n) ∂x (n) | = p(η (m) , η (n) | z (m) )|det ∂η (m) ∂x (m) ||det ∂η (n) ∂x (n) | LHS = == ⇒ p(x (m) | z (m) )p(x (n) | z (m) ) = p(x (m) , z (m) ) p(z (m) ) p(x (n) , z (m) ) p(z (m) ) = p(η (m) , z (m) ) p(z (m) ) |det ∂η (m) ∂x (m) | p(η (n) , z (m) ) p(z (m) ) |det ∂η (n) ∂x (n) | = p(η (m) | z (m) )p(η (n) | z (n) )|det ∂η (m) ∂x (m) ||det ∂η (n) ∂x (n) | Thus we have p(η (m) , η (n) |z (m) ) = p(η (m) |z (m) )p(η (n) |z (n) ) ⇒ p(η (m) , η (n) ) = p(η (m) )p(η (n) ) ⇒ η (m) ⊥ ⊥ η (n)</formula><p>Necessary condition. Given RHS of Eq. ( <ref type="formula" target="#formula_29">7</ref>) and above conclusion, we have</p><formula xml:id="formula_33">p(x (m) | z (m) ) = p(η (m) )|det ∂η (m) ∂x (m) |, p(x (n) | z (m) ) = p(η (n) )|det ∂η (n) ∂x (n) | M ultiplication = ========= ⇒ p(x (m) | z (m) )p(x (n) | z (m) ) = p(η (m) )p(η (n) )|det ∂η (m) ∂x (m) ||det ∂η (n) ∂x (n) | = p(η (m) , η (n) )|det ∂η (m) ∂x (m) ||det ∂η (n) ∂x (n) | = p(η (m) , η (n) , z (m) ) p(z (m) ) |det ∂η (m) ∂x (m) ||det ∂η (n) ∂x (n) | = p(x (m) , x (n) , z (m) ) p(z (m) ) ⇒ p(x (m) | z (m) )p(x (n) | z (m) ) = p(x (m) , x (n) | z (m) ) ⇒ x (m) ⊥ ⊥ x (n) | z (m)<label>(8)</label></formula><p>Proposition B.2 (Independent Noise Condition). Let z and η be the block-identified latent variables and domain-specific information, respectively, across all modalities. Denote ϵ as the exogenous variables in the latent causal structure. We have</p><formula xml:id="formula_34">η ⊥ ⊥ z ⇐⇒ η ⊥ ⊥ ϵ.<label>(9)</label></formula><p>Proof. Given the causal function in Eq. ( <ref type="formula" target="#formula_13">1</ref>), we have p(z) = p(ϵ)|det ∂ϵ ∂z |. Sufficient condition. Suppose (z, η) = h(ϵ, η) and η ⊥ ⊥ z, we have</p><formula xml:id="formula_35">p(z, η) = p(ϵ, η)|def ∂ϵ ∂z | ⇒ p(z)p(η) = p(ϵ, η)|def ∂ϵ ∂z | ⇒ p(ϵ)p(η)|det ∂ϵ ∂z | = p(ϵ, η)|def ∂ϵ ∂z | ⇒ p(ϵ)p(η) = p(ϵ, η) ⇒ η ⊥ ⊥ ϵ (10)</formula><p>Necessary condition. Suppose (z, η) = h(ϵ, η) and η ⊥ ⊥ ϵ, we have</p><formula xml:id="formula_36">p(z, η) = p(ϵ, η)|def ∂ϵ ∂z | ⇒ p(z, η) = p(ϵ)|def ∂ϵ ∂z |p(η) ⇒ p(z, η) = p(z)p(η) ⇒ η ⊥ ⊥ z (11) C IDENTIFIABILITY THEORY C.1 PROOF FOR THEOREM 4.2</formula><p>We present the proof for Theorem 4.2. For ease of reference, we duplicate Condition 4.1 and Theorem 4.2 below. Condition 4.1 (Subspace Identifiability Conditions).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A1 [Smoothness &amp; Invertibility]:</head><p>The generating functions g x (m) and g(m) are smooth and have smooth inverse functions.</p><p>A2 [Linear Independence]: The generating function gx (-m) is smooth and its Jacobian columns corresponding to z (m) (i.e., [J gx (-m) ] :,I(z (m) ) ) are linearly independent almost anywhere.</p><p>Theorem 4.2 (Subspace Identifiability). Let θ := {g x (m) , gz (-m) , p(ϵ (m) ), p(ε (-m) )} M m=1 and θ := {ĝ x (m) , ĝz (-m) , p(ε (m) ), p( ε(-m) )} M m=1 be two specifications of the data-generating process in Eq. (3). Suppose that they generate identical observational distributions (i.e., p(x) = p(x)), θ satisfies Condition 4.1, and θ satisfies Condition 4.1-A1. The latent subspace ẑ(m) for any group m and its counterpart z (m) are equivalent up to an invertible map h (m) (•), i.e., ẑ(m) = h (m) (z (m) ).</p><p>Proof. Given the generating processes in Eq. ( <ref type="formula" target="#formula_2">2</ref>) and Eq. ( <ref type="formula" target="#formula_13">1</ref>), we can express any observed group x (m) and its complement x (-m) := x \ x (m) as two views of the latent variables of group m:</p><formula xml:id="formula_37">x (m) := g (m) (z (m) , η (m) ),<label>(12)</label></formula><p>x (-m) </p><formula xml:id="formula_38">:= g (-m) (z (m) , η(-m) ), ,<label>(13)</label></formula><p>where η (m) stands for exogenous variables for the group x (m) and η(-m) represents all the information necessary to generate the complement group x (-m) beyond z (m) .</p><p>Following the classic definition of identifiability, we define two specifications θ = {g x (m) , g z (m) , p(ϵ (m) )} M m=1 and θ := {ĝ x (m) , ĝz (m) , p(ϵ (m) )} M m=1 that fit the observation distribution p(x). To show the identifiability in terms of the functions in θ and θ, we show that given the same x (m) value the identifiability between z (m) and ẑ(m) . Thus, the subspace identification is equivalent to show that for each group m, the estimated latent variable ẑ(m) and the true counterpart are related via an invertible map h, i.e., ẑ(m) = h(z (m) ).</p><p>Eq. ( <ref type="formula" target="#formula_37">12</ref>) and the invertibility of the map (z, η (m) , η(-m) ) → (x (m) , x (-m) ) (Condition 4.1-A1) give rise to an invertible map h : (ẑ (m) , η(m) , η(-m) ) → (z (m) , η m , η(-m) ).</p><p>The matched observed distribution between the true and the estimated models for the generating process Eq. ( <ref type="formula" target="#formula_38">13</ref>) yields that</p><formula xml:id="formula_39">g (-m) (z (m) , η(-m) ) = ĝ(-m) (ẑ (m) , η(-m) ). (<label>14</label></formula><formula xml:id="formula_40">)</formula><p>Plugging in h gives</p><formula xml:id="formula_41">ĝ(-m) (ẑ (m) , η(-m) ) = g (-m) h ẑ(m) , η(m) , η(-m) I(z (m) ),I( η(-m) ) . (<label>15</label></formula><formula xml:id="formula_42">)</formula><p>where we adopt I(•) to indicate the indices of its argument.</p><p>For any i ∈ [d(x (m) )] and j ∈ [d( η(m) )], we take partial derivative w.r.t. η(m) j on both sides of Eq. ( <ref type="formula" target="#formula_41">15</ref>):</p><formula xml:id="formula_43">∂[ĝ (-m) ] i ∂[η (m) ] j =0 = ∂[g (-m) ] i ∂[η (m) ] j . (<label>16</label></formula><formula xml:id="formula_44">)</formula><p>The left-hand side of Eq. ( <ref type="formula" target="#formula_41">15</ref>) equals to zero because ĝ(-m) is not a function of η(m) .</p><p>Therefore, expanding the right-hand side of Eq. ( <ref type="formula" target="#formula_41">15</ref>) gives:</p><formula xml:id="formula_45">k∈I(z (-m) )∪I( η(-m) ) ∂[g (-m) ] i ∂[ h] k • ∂[ h] k ∂[η (m) ] j = k∈I(z (-m) ) ∂[g (-m) ] i ∂[ h] k • ∂[ h] k ∂[η (m) ] j = 0. (<label>17</label></formula><formula xml:id="formula_46">)</formula><p>The first equality in Eq. ( <ref type="formula" target="#formula_45">17</ref>) is due to the fact that η(-m) is a function of x (-m) and varying η(m) doesn't vary x (-m) ( η(m) is a function of x (m) thanks to the invertibility of ĝ(m) ), i.e., ∂[η (-m) </p><formula xml:id="formula_47">] k ∂[η (m) ]j = 0. Condition 4.1-A2 implies that the matrix ∂[g (-m) ]i ∂[ h] k i,k</formula><p>has a full column rank. Therefore, its null space contains only a zero vector, which, together with Eq. ( <ref type="formula" target="#formula_45">17</ref>), implies that ∂[z (m) ] k ∂[η (m) ]j = 0. Consequently, given the generating process Eq. ( <ref type="formula" target="#formula_37">12</ref>) and the invertibility of g (m) and ĝ(m) (Condition 4.1-A1), the estimated latent variable ẑ(m) and the true latent variable z (m) are related via an invertible map, as desired.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 PROOF FOR THEOREM 4.4</head><p>We present the proof for Theorem 4.4. For ease of reference, we duplicate Condition 4.3 and Theorem 4.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Condition 4.3 (Component Identifiability Conditions</head><p>). Over the domain of (z, ϵ), for any modality m and any T ̸ ∈ P(d(z)), we have</p><formula xml:id="formula_48">m̸ =n∈[M ] T -1 m [G] (m),(n) T n 0 &gt; m̸ =n∈[M ] [G] (m),(n) 0 . (<label>4</label></formula><formula xml:id="formula_49">)</formula><p>Theorem 4.4 (Component-wise Identifiability). Let θ := ({g x (m) , g z (m) , p(ϵ (m) )} M m=1 ) and θ := ({ĝ x (m) , ĝz (m) , p(ϵ (m) )} M m=1 ) be two specifications of the data-generating process in Eq. (1) and Eq. (2). Suppose that they generate identical observational distributions (i.e., p(x) = p(x)) and θ satisfies Condition 4.1 and Condition 4.3. If θ satisfies the following sparse regularization condition:</p><formula xml:id="formula_50">m̸ =n∈[M ] [ Ĝ] (m),(n) 0 ≤ m̸ =n∈[M ] [G] (m),(n) 0 ,<label>(5)</label></formula><formula xml:id="formula_51">each component z (m) i</formula><p>and its counterpart ẑ(m) π(i) are equivalent up to an invertible map h(•), i.e., ẑ(m)</p><formula xml:id="formula_52">π(i) = h(z (m) i ) under a permutation π over [d(z (m) )].</formula><p>Proof. Given Theorem 4.2, Condition 4.1 implies that the estimated group-wise latent variable ẑ(m) is related to the true variable z (m) through an invertible transformation h (m) , i.e.,</p><formula xml:id="formula_53">ẑ(m) = h (m) (z (m) ). (<label>18</label></formula><formula xml:id="formula_54">)</formula><p>It follows that the Jacobian matrix T ∂ẑ ∂z can be arranged into a block-diagonal matrix, in which diagonal block m corresponds to a Jacobian matrix T ∂ẑ (m) ∂z (m)</p><p>. Then, the goal is to prove that these diagonal blocks are actually generalized permutation matrices, whose each column only contains one nonzero entry.</p><p>We divide the proof into several steps for the sake of exposition. At step 1, we derive an equivalence relation between the estimation model (ĝ z , ĝx ) and the true model (g z , g x ). At step 2, we apply Theorem 4.2 to the equivalence to characterize the relation between the true and the estimated graph structure. At step 3, we leverage the sparsity condition (Condition 4.3) to reason about the identifiability of each component z</p><formula xml:id="formula_55">(m) i for m ∈ [M ] and i ∈ [d(z (m) )].</formula><p>Step 1. The generating process in Eq. ( <ref type="formula" target="#formula_13">1</ref>) and the subspace identification Eq. ( <ref type="formula" target="#formula_53">18</ref>) imply</p><formula xml:id="formula_56">ĝz (ẑ, ε) = h • g z (z, ϵ), (<label>19</label></formula><formula xml:id="formula_57">)</formula><p>where h is defined as the Cartesian product of individual h (m) functions.</p><p>Taking partial derivatives w.r.t, z i of both sides of Eq. ( <ref type="formula" target="#formula_56">19</ref>) yields:</p><formula xml:id="formula_58">G ∂ẑ ∂ẑ T ∂ẑ ∂ ε T ∂ẑ ∂z T ∂ ε ∂z = T ∂ẑ ∂z G ∂z ∂z . (<label>20</label></formula><formula xml:id="formula_59">)</formula><p>Each T matrix is the Jacobian matrix consisting of the corresponding partial derivatives. We use G ∂z ∂z to denote the derivatives from the function g z which encodes the dependence structure among z components. The same applies to G ∂ẑ ∂ẑ . As discussed above, the matrix T ∂ẑ ∂z has a block-diagonal structure (after proper permutations) with block m corresponding to the Jacobian matrix of h (m) . Moreover, the matrix T ∂ẑ ∂ ε is strictly diagonal due to the generating function Eq. ( <ref type="formula" target="#formula_13">1</ref>).</p><p>Step 2. In this step, we simplify Eq. ( <ref type="formula" target="#formula_58">20</ref> First, we note that the T ∂ ε ∂z is also block-diagonal w.r.t. the groups. To see this, we compute the partial derivatives therein as follows:</p><formula xml:id="formula_60">∂ε (m) i ∂z (n) j = ∂ε (m) i ∂ ẑ(m) i ∂ ẑ(m) i ∂z (n) j</formula><p>, where we denote that output of ĝz with z in the derivative. Due to the equivalent relation z = z (Eq. ( <ref type="formula" target="#formula_13">1</ref>)), we have</p><formula xml:id="formula_61">∂ ẑ(m) i ∂z (n) j = ∂ ẑ(m) i ∂z (n) j</formula><p>which is zero for distinct groups m ̸ = n (Eq. ( <ref type="formula" target="#formula_53">18</ref>)). It follows that </p><formula xml:id="formula_62">∂ε (m) i ∂z (n) j = 0, m ̸ = n.<label>(21</label></formula><formula xml:id="formula_63">G ∂ẑ ∂ẑ T ∂ẑ ∂z (m),(n) = T ∂ẑ ∂z G ∂z ∂z (m),(n) , m ̸ = n,<label>(22)</label></formula><p>where we adopt subscripts (m) to denote the block for group m.</p><p>On account of the block-diagonal structure of T ∂ẑ ∂z , the left-hand side of Eq. ( <ref type="formula" target="#formula_63">22</ref>) can be expressed as follows:</p><formula xml:id="formula_64">G ∂ẑ ∂ẑ T ∂ẑ ∂z (m),(n) = G ∂ẑ ∂ẑ (m),: T ∂ẑ ∂z :,(n) = G ∂ẑ ∂ẑ (m),(n) T ∂ẑ ∂z (n),(n) . (<label>23</label></formula><formula xml:id="formula_65">)</formula><p>Analogously, the right-hand side of Eq. ( <ref type="formula" target="#formula_63">22</ref>) can be expressed as:</p><formula xml:id="formula_66">T ∂ẑ ∂z G ∂z ∂z (m),(n) = T ∂ẑ ∂z (m),: G ∂z ∂z :,(n) = T ∂ẑ ∂z (m),(m) G ∂z ∂z (m),(n) . (<label>24</label></formula><formula xml:id="formula_67">)</formula><p>It follows from Eq. ( <ref type="formula" target="#formula_63">22</ref>), Eq. ( <ref type="formula" target="#formula_64">23</ref>), and Eq. ( <ref type="formula" target="#formula_66">24</ref>) that</p><formula xml:id="formula_68">G ∂ẑ ∂ẑ (m),(n) T ∂ẑ ∂z (n),(n) = T ∂ẑ ∂z (m),(m) G ∂z ∂z (m),(n) =⇒ G ∂ẑ ∂ẑ (m),(n) = T ∂ẑ ∂z (m),(m) G ∂z ∂z (m),(n) T ∂z ∂ẑ (n),(n) . (<label>25</label></formula><formula xml:id="formula_69">)</formula><p>Eq. ( <ref type="formula" target="#formula_68">25</ref>) relates the true off-diagonal (m</p><formula xml:id="formula_70"≯ = n) structure G ∂z ∂z (m),(n)</formula><p>and its estimated counterpart</p><formula xml:id="formula_71">G ∂ẑ ∂ẑ (m),(n)</formula><p>.</p><p>Step 3. We now reason about the component-wise identifiability within each modality through the sparsity of the off-diagonal regions.</p><p>The component-wise identifiability is equivalent to that each block sub-matrix T ∂ẑ ∂z (m),(m) is a generalized permutation matrix, each row/column of which contains only one nonzero element. Suppose that this was not the case, then it would follow from Eq. ( <ref type="formula" target="#formula_68">25</ref>) and Condition 4.3 that</p><formula xml:id="formula_72">m̸ =n∈[M ] G ∂ẑ ∂ẑ (m),(n) 0 = m̸ =n∈[M ] T ∂ẑ ∂z (m),(m) G ∂z ∂z (m),(n) T ∂z ∂ẑ (n),(n) 0 &gt; Condition 4.3 m̸ =n∈[M ] G ∂z ∂z (m),(n) 0 ,<label>(26)</label></formula><p>which would violate the sparsity constraint Eq. ( <ref type="formula" target="#formula_19">5</ref>).</p><p>That is, the component ẑ(m)</p><formula xml:id="formula_73">î cannot functionally influence components in U (m) other than z (m) i</formula><p>.</p><p>Therefore, we have shown that each block sub-matrix T ∂ẑ ∂z (m),(m) is a generalized permutation matrix. Consequently, we have a bijection ẑ(m)</p><formula xml:id="formula_74">î = h<label>(m) î (z (m) i</label></formula><p>). Since this holds for any group m and any component i, we have arrived at the desired conclusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3 EXTENDED THEOREM 4.2 AND ITS PROOF</head><p>We restate Theorem C.5 from <ref type="bibr" target="#b77">Yao et al. (2023)</ref>, which we invoke in our Theorem C.7. We drop the entropy regularization term in <ref type="bibr" target="#b77">Yao et al. (2023)</ref>, since we assume the invertibility of estimated functions ĝ(m) directly. Definition C.1 (View-Specific Encoders). The view-specific encoders R := {r k : X k → Z S k } k∈V consist of smooth functions mapping from the respective observation spaces to the view-specific latent space, where the dimension of the k th latent space</p><formula xml:id="formula_75">|S k | is assumed known for all k ∈ V . Definition C.2 (Selection). A selection ⊘ operates between two vectors a ∈ {0, 1} d , b ∈ R d s.t. a ⊘ b := [b j : a j = 1, j ∈ [d]] Definition C.3 (Content Selectors). The content selectors Φ := {ϕ(i, k)} Vi∈V,k∈Vi with ϕ (i,k) ∈ {0, 1} |d(z (m) )| perform selection C.2 on the encoded information: for any subset V i ⊂ [M ] and view k ∈ V i we have the selected representation: ϕ(i, m) ⊘ ẑ(m) with ϕ (i,k) 0 = ϕ (i,k ′ ) 0 for all V i ∈ V, k, k ′ ∈ V i .</formula><p>Definition C.4 (Information-Sharing Regularizer). The following regularizer penalizes the ℓ 0norm ∥•∥ 0 of the content selectors Φ: Reg(Φ) := -Vi∈V k∈Vi ϕ (i,k) 0 . Theorem C.5 (View-Specific Encoder for Identifiability <ref type="bibr" target="#b77">(Yao et al., 2023)</ref>). Let R := {ĝ (m) } M m=1 and Φ respectively be the generating functions and content selectors (Definition C.3) that solve the following constrained optimization problem:</p><formula xml:id="formula_76">min Reg(Φ) subject to: R, Φ ∈ arg min L alignment (R, Φ) ,<label>(27)</label></formula><p>where</p><formula xml:id="formula_77">L alignment (R, Φ) = Vi∈V m1,m2∈Vi k&lt;k ′ E ϕ(i, m 1 ) ⊘ [ĝ (m1) ] -1 (x k ) -ϕ(i, m 2 ) ⊘ [ĝ m2 ] -1 (x m2 ) 2<label>(28</label></formula><p>) Then for any subset of modalities V i ⊂ [M ] and any modality m ∈ V i , ϕ(i, m) ⊘ [ĝ (m) ] -1 identifies the shared subspace z (∩m∈V i m) . Definition C.6 (Reconstruction Loss). The following loss penalizes the deviation of the estimate x and its corresponding true counterpart x in ℓ 2 L recons := E x (x -x) .</p><p>Notice that at the absence of the shared block (m ∩ n), Condition C.8 recovers Condition 4.3 where</p><formula xml:id="formula_78">E(m) = B \ {m} and H(m \ n) = m, and H(n \ m) = n. Theorem C.9 (Generalized Component-wise Identifiability). Let θ := ({g x (m) , g z (m) , p(ϵ (m) )} M m=1</formula><p>) and θ := ({ĝ x (m) , ĝz (m) , p(ϵ (m) )} M m=1 ) be two specifications of the data-generating process in Eq. (1) and Eq. (2) with potentially shared variables z (m∩n)  over any modalities m and n. Suppose that they generate identical observational distributions (i.e., p(x) = p(x)) and θ satisfies Condition 4.1 and Condition C.8. If θ satisfies the following condition:</p><formula xml:id="formula_79">b∈B, b∈E(b) [ Ĝ] ( b),(b) 0 ≤ b∈B, b∈E(b) [G] ( b),(b) 0 , (<label>30</label></formula><formula xml:id="formula_80">)</formula><formula xml:id="formula_81">each component z (m) i</formula><p>and its counterpart ẑ(m) π(i) are equivalent up to an invertible map h(•), i.e., ẑ(m)</p><formula xml:id="formula_82">π(i) = h(z (m) i ) under a permutation π over [d(z (m) )].</formula><p>Proof. This proof closely follows that of Theorem 4.4. We illustrate the key discrepancies as follows.</p><p>We start with only two modalities z (m) and z (n) for simplicity and then move on to general cases.</p><p>The structure of the indeterminacy matrix T ∂ẑ ∂z . Identical to Equation <ref type="formula" target="#formula_58">20</ref>, we have the relationship between Jacobian matrices:</p><formula xml:id="formula_83">G ∂ẑ ∂ẑ T ∂ẑ ∂ ε T ∂ẑ ∂z T ∂ ε ∂z = T ∂ẑ ∂z G ∂z ∂z .<label>(31)</label></formula><p>The presence of the shared block z (m∩n) alters the indeterminacy matrix T ∂ẑ ∂z -instead of the disjoint diagonal-block shape, T ∂ẑ ∂z , the columns belonging to the shared variables z (m∩n) (shared between two modalities) are possibly nonzero over rows belonging to z (m∩n) . That is, the shared variables z (m∩n) can still mix in the estimates of the two individual parts ẑ(m\n) and ẑ(n\m) . However, since we have identified the subspace of z (m∩n) , its estimates would not contain information of the individual blocks z (m\n) and z (n\m) , rendering the blocks ∂ẑ (m∩n) ∂z (m\n) = 0 and ∂ẑ (m∩n) ∂z (n\m) = 0.</p><p>The sparse connection among modalities. The reasoning in Step 2 in the proof of Theorem 4.4 implies that the structure of the matrix T ∂ ε ∂z is consistent with that of the matrix T ∂ẑ ∂z . That is, they have zero block matrices at the same positions. In particular, since the subspace identifiability in Theorem C.7 implies that the estimated shared variable ẑ(m∩n) and the modality-specific variable ẑ(n\m) are not influenced by the other modality-specific variables z (m\n) , the same applies to the estimated exogenous variable ε(m∩n) and ε(m\n) . This structure permits us to disregard T ∂ẑ ∂ ε (an identity matrix) and T ∂ ε ∂z on the left-hand side of Eq. ( <ref type="formula" target="#formula_83">31</ref>) when computing a sub-matrix of the right-hand side product:</p><formula xml:id="formula_84">G ∂ẑ ∂ẑ T ∂ẑ ∂z (n),(m\n) = T ∂ẑ ∂z G ∂z ∂z (n),(m\n) . (<label>32</label></formula><formula xml:id="formula_85">)</formula><p>We further divide the block [(n), (m \ n)] into two blocks along their rows:</p><formula xml:id="formula_86">[(m ∩ n), (m \ n)] and [(n \ m), (m \ n)]</formula><p>that represent the influence from z (m\n) to ẑ(m∩n) and ẑ(n\m) . </p><p>Analogously, this block on the right-hand side of Eq. ( <ref type="formula" target="#formula_84">32</ref>) can be expressed as: </p><formula xml:id="formula_88">T ∂ẑ ∂z G ∂z ∂z<label>(</label></formula><p>This graphical relation is identical to that in Eq. ( <ref type="formula" target="#formula_68">25</ref>).</p><p>However, the relation for the block [(n \ m), (m \ n)] between two modality-specific parts varies, due to the potential mixing of the shared part into these blocks, which may increase the inbound edges (not outbound edges), as we show below.</p><p>For the block [(n \ m), (m \ n)] on the left-hand side of Eq. ( <ref type="formula" target="#formula_84">32</ref>) gives: .</p><p>(</p><formula xml:id="formula_90">)<label>36</label></formula><p>Unlike previous cases, the right-hand side of Eq. ( <ref type="formula" target="#formula_84">32</ref>) for the block involves more than atomic blocks (i.e., it involves the entire modality (n)):</p><formula xml:id="formula_91">T ∂ẑ ∂z G ∂z ∂z (n\m),<label>(m\n)</label></formula><p>= T ∂ẑ ∂z (n\m),:</p><formula xml:id="formula_92">G ∂z ∂z :,(m\n) = T ∂ẑ ∂z (n\m),(n) G ∂z ∂z (n),<label>(m\n)</label></formula><p>.</p><p>Then, it follows from Eq. ( <ref type="formula" target="#formula_90">36</ref>) and Eq. ( <ref type="formula" target="#formula_93">37</ref>) that .</p><p>We can observe that the existence of the shared variables z (m∩n) divides the latent space into finer blocks z (m\n) , z (n\m) , and z (m∩n) . Eq. ( <ref type="formula" target="#formula_89">35</ref>) and Eq. ( <ref type="formula" target="#formula_94">38</ref>) reveal that the bijective indeterminacy relation hold over these finer blocks, exception for the non-square transition matrix T ∂ẑ ∂z (n\m),(n)</p><p>on the right-hand side of Eq. ( <ref type="formula" target="#formula_94">38</ref>). This is because that the shared part z (m∩n) can potentially mix in ẑ(n\m) , so ẑ(n\m) may receive edges inbound to z (m∩n) .</p><p>Interplay among multiple modalities. In light of the graphical condition for the two-modality case (Eq. ( <ref type="formula" target="#formula_89">35</ref>) and Eq. ( <ref type="formula" target="#formula_94">38</ref>)), we can derive the conditions for the multi-modality case. Eq. ( <ref type="formula" target="#formula_89">35</ref>) and Eq. ( <ref type="formula" target="#formula_94">38</ref>) reveal that the sparsity for Region 1 and Region 2 is informative, whereas Region 3 is not. This is because in these the inherent indeterminacy from the subspace identifiability within each modality (Theorem 4. With these modifications, the rest of the proof follows exactly from that of Theorem 4.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D EXPERIMENTAL DETAILS D.1 NUMERICAL DATASET</head><p>We use six numerical datasets in this paper, including three multimodal datasets that satisfy our assumptions and three that slightly violate the sparsity assumptions in the proposed theorems.</p><p>Multi-modality settings We generate n = 10000 samples according to Eq. ( <ref type="formula" target="#formula_13">1</ref>) and Eq. ( <ref type="formula" target="#formula_2">2</ref>). Following prior work <ref type="bibr" target="#b70">(Von Kügelgen et al., 2021;</ref><ref type="bibr" target="#b78">Yao et al., 2021;</ref><ref type="bibr" target="#b90">Zimmermann et al., 2021)</ref>, we generate observations using a multi-layer perceptron (MLP). Specifically, the mixing function g is modeled as a three-layer MLP with randomly initialized weights and leaky ReLU activations, enabling g to represent a general nonparametric mixing function. The causal noise terms ϵ are independently and identically distributed (i.i.d.), and the exogenous variables are mutually independent. Sparse inter-modality causal dependencies are randomly generated, ensuring that each modality's latent variables maintain at least one causal connection with another modality.</p><p>Ablation settings For the ablation study, we generate two modality observations under different sparsity ratios. Each observation is generated from three causally related latent variables and one exogenous variable. The sample size for each dataset is set to n = 10000, and the dimensionality of the observations in each modality is d(x) = 20. The sparsity ratio determines the extent of intermodality connections among these latent variables. A higher sparsity ratio leads to a sparser causal structure, meaning fewer causal connections between latent variables. Conversely, a lower sparsity ratio yields a denser causal matrix with more causal dependencies. For example, a sparsity ratio of 0% indicates that all inter-modality latent variables are fully connected, whereas a sparsity ratio of 50% implies that half of the possible causal edges are removed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2 SYNTHETIC DATASET</head><p>Variant MNIST In real-world scenarios, the ground-truth latent processes are often unknown, making it challenging to evaluate model performance. To address this, we construct a synthetic dataset based on the real image dataset MNIST (LeCun, 1998) with known causal relationships, which supports the setting considered in our work. Our synthetic dataset consists of two modalities, each with latent variables that exhibit causal relationships. The design is flexible. The modalities could correspond to different MNIST variants, such as colored MNIST <ref type="bibr" target="#b2">(Arjovsky et al., 2019)</ref> or fashion MNIST <ref type="bibr" target="#b74">(Xiao et al., 2017)</ref>. The causally related latent variables could be, for example, digit identity, image color, clothing category, image rotation, etc.</p><p>In order to make the synthetic setting more intuitive, we introduce an alternative setting: object position acts as a latent variable that influences the appearance of MNIST images. Across different modalities, such causal influence may vary. Furthermore, position in modality 1 may causally influence position in modality 2, which aligns with the data generation process in our work. For example, the horizontal position of a digit -such as the six -directly influences the transparency of the MNIST image. This horizontal position then serves as a causal factor for the vertical position of shoes in the fashion MNIST, which in turn affects the grayscale intensity of the shoe image. To systematically evaluate the performance of our algorithm under different observational conditions, we consider three variations in colored MNIST, where the digits are assigned one of three colors: red, green, or blue. These relationships are visually illustrated in Figure <ref type="figure" target="#fig_18">7</ref>   Fundus imaging is the visualization of the interior surface of the fundus, which includes structures such as the optic disc, retina, and retinal microvasculature. High-resolution images of the back of the eye are essential for the diagnosis and monitoring of a variety of eye diseases and conditions.</p><p>For example, the retinal microvasculature, which consists of small blood vessels that supply blood to the retina, provides valuable information about eye health. Moreover, fundus imaging can improve understanding of the underlying mechanisms of various eye diseases. It serves as a non-invasive tool to assess the overall health of the microvascular circulation health and provides a direct view of part of the central nervous system. factors and the estimated latent variables. Specifically, MCC first computes the absolute values of the correlation coefficients between each ground-truth factor and each estimated latent variable. To account for possible permutations of the latent variables, the metric solves a linear sum assignment problem on the computed correlation matrix in polynomial time, ensuring optimal matching between the factors and their corresponding latent representations.</p><p>R2: Coefficient of Determination R2 is a standard metric used to evaluate the goodness of fit in regression models. It measures the proportion of variance in the dependent variable that is explained by the independent variables in the model. Specifically, R2 compares the residual sum of squares of the model with the total sum of squares and returns a value between 0 and 1. A higher R2 indicates that the model explains a larger portion of the variance in the data, with 1 representing a perfect fit and 0 indicating that the model explains none of the variability.</p><p>SHD: Structural Hamming Distance SHD is a widely used metric for evaluating the accuracy of graph structure recovery in causal discovery. It quantifies the difference between the true causal graph and the estimated graph. Specifically, SHD counts the number of edge modifications-additions, deletions, or reversals-required to transform the estimated graph into the groundtruth graph. This metric provides a simple yet effective measure of structural similarity, with a lower SHD indicating a closer alignment between the estimated and true causal structures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.5 DETAILED DISCUSSION ON HUMAN PHENOTYPE</head><p>Without learning such latent variables, we cannot provide a causal explanation between different modalities. The estimated model shows all causal influences involved, suggests the existence of hidden causal variables, and illustrates their relationships with each other and with observable data. Asymptotically, the learned adjacency matrix A corresponds to a graph within the Markov equivalence class given by the PC algorithm.</p><p>To interpret the learned hidden variables, we primarily refer to the existing medical literature, which supports their alignment with background knowledge, thereby adding validity to our results. For example, the latent variable FRight3 relates handgrip strength to fundus imaging, consistent with findings showing that handgrip strength correlates with intraocular pressure (IOP) <ref type="bibr" target="#b56">(Pérez-Castilla et al., 2021)</ref>. In addition, the association between the cataract and changes in IOP <ref type="bibr" target="#b63">(Slabaugh et al., 2013)</ref> is consistent with the findings of the model. These connections underline the physiological relevance of the learned hidden variable. Similarly, FRight1 and FLeft1, associated with fundus imaging and age estimation, are consistent with studies demonstrating age-related changes in fundus image color content <ref type="bibr" target="#b14">(Ege et al., 2002)</ref>. Another latent variable Sleep1 associated with oxygen saturation and sleep metrics aligns with findings that oxygen saturation is a strong predictor of obstructive sleep apnea (OSA) severity <ref type="bibr" target="#b71">(Wali et al., 2020)</ref>. This indicates that the model's latent variable effectively captures critical factors related to sleep disorders.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E EXTENDED EXPERIMENT</head><p>To further assess the robustness, scalability, and applicability of our proposed method, we conducted a series of extended experiments under more complex scenarios. These experiments aim to evaluate the performance under diverse latent variable configurations, varying sample sizes, and different structural assumptions, including non-DAG settings and shared latent variables.</p><p>Performance in complex scenarios. To evaluate the scalability and generalizability of our method to complex causal structures, we conducted additional experiments on higher-dimensional simulated tasks with diverse configurations of latent variables and modalities. These setups introduce significantly more complex causal relationships between variables. Specifically, we consider three extended scenarios: (1) Five-mods, with 30-dimensional observations from five modalities with two latent variables and one exogenous variable per modality. (2) Six-mods, with 30-dimensional observations from six modalities with two latent variables and one exogenous variable per modality. (3) Eight-mods, involving 30-dimensional observations from eight modalities with two latent variables and one exogenous variable per modality. The results, summarized in Table <ref type="table" target="#tab_6">4</ref>, show that our method consistently delivers robust performance under these challenging conditions.</p><p>Impact of the number of latent variables. In real-world applications, the true number of latent variables is typically unknown, and arbitrarily predefining this number may introduce bias and degrade model performance. In this section, we discuss how our method can eliminate the redundant effect of the latent variables, and introduce a cross-validation-based method to determine the appropriate number of latent nodes. By manually setting a range for the number of latent variables and selecting the one with the lowest validation loss, we ensure a principled approach that is both simple and widely applicable <ref type="bibr">(Khemakhem et al., 2020b)</ref>. Here we conduct synthetic experiments to validate its effectiveness. We followed the data generation process in Section D.1, where the ground-truth number of latent variables is two per modality. The results, as shown in Figure <ref type="figure" target="#fig_19">8</ref>(a), demonstrate that our approach accurately recovers the correct number of latent variables.</p><p>Impact of sample size. To investigate the impact of sample size on model performance, we conducted an additional experiment evaluating the MCC as the number of data samples increased. Following the data generation process described in Section D.1, where the ground-truth number of latent variables is two for two modalities. We systematically increased the sample size from 10,000 to 40,000 and measured MCC and R2 accordingly. The results, presented in Figure <ref type="figure" target="#fig_19">8</ref>(b), show a consistent improvement in MCC as the sample size increases. This finding confirms the hypothesis that greater data availability enhances the model's ability to recover the underlying causal structure. Evaluation under non-DAG assumptions. The theoretical results in this paper do not strictly require the assumption of Directed Acyclic Graphs (DAGs) for latent variable structures within or across modalities. To evaluate our method under non-DAG settings, we conducted synthetic experiments where cycles were introduced within and across modalities. Specifically, we followed the data generation process in Section D.1, and considered: (1) cyclic influence within modality; and</p><p>(2) cyclic influence across modalities. Empirical results in Table <ref type="table" target="#tab_6">4</ref> demonstrate that the presence of cycles does not hinder the identification of latent variables.</p><p>Discussion on the shared latent variables. We present how to preprocess the current framework to accommodate shared variables across modalities and provide empirical results. The extended framework incorporates an additional mechanism to estimate the shared latent variable. Inspired by previous works <ref type="bibr" target="#b77">(Yao et al., 2023;</ref><ref type="bibr" target="#b12">Daunhawer et al., 2023;</ref><ref type="bibr" target="#b70">Von Kügelgen et al., 2021)</ref>, we incorporate an additional contrastive loss to enforce similarity in the shared latent representations. To evaluate the effectiveness of this extension, we modify the data generation process in Section D.1 and allow for the existence of a shared variable across modalities. The results, summarized in Table 4, show that our method accurately recovers both shared and modality-specific latent variables across different scenarios, confirming the theoretical guarantees of the extended framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F IMPLEMENTATION DETAILS</head><p>In this section, we provide details of the network architecture, including the optimization scheme and hyperparameter setting. We summarize our network architecture below and describe it in detail in Table <ref type="table">5</ref>.</p><p>• (1,2) Encoder and Decoder: The encoder transforms raw observations into latent representations, while the decoder reconstructs the inputs from the latent variables. The encoder-decoder design varies depending on the downstream task. For synthetic data, MLPs with leaky ReLU activation were used. For image data, CNN was used as the encoder, and ConvTranspose2D as the decoder.</p><p>LSTMs were used for time series data. Based on the universal approximation theorem, the model is theoretically able to approximating the underlying mixing function. • (3) Learnable Adjacency Matrix: The causal relationships are embedded in the learned adjacency matrix, where the binary elements indicate whether specific pairs of vertices contribute to the generation of components. It initializes a learnable matrix that captures these dependencies. During the forward pass, the matrix is processed to ensure a directional structure where only certain connections are allowed based on a threshold. This allows the model to learn sparse, meaningful relationships between the latent variables. • (4) Flow-based Transformation: The flow-based transformation is implemented using an MLP to process the latent variable and a flow model for the transformation. The MLP first extracts features from the latent variable, which are then used as input to the flow model, which applies an invertible transformation to the latent space, allowing the model to estimate the noise distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.2 TRAINING DETAILS</head><p>Optimization Scheme. The estimation framework was trained using the Adam optimizer on GPU, and the StepLR scheduler was used to reduce the learning rate periodically. The training process ran for a maximum of 10000 epochs, with early stopping applied if the validation loss does not improve for 20 consecutive epochs. Random seeds were used to ensure reproducibility, and results were averaged across experiments, with variance reported.</p><p>The training loss combines multiple components.</p><p>• Reconstruction loss: Mean squared error between reconstructed inputs and original data.</p><p>• KL divergence loss: Encourages estimated variables to follow a standard normal prior.</p><p>• Sparsity loss: An L1-norm penalty is applied to the adjacency matrix to enforce sparsity.</p><p>Hyperparameter. The hyperparameters α = [α Ind , α Sp , α Recon ] represent the weights assigned to each term in the composite objective function. For each dataset, they were tuned within appropriate logarithmic intervals, ensuring a balance between independence, sparsity, and reconstruction. For the experiments, the following settings were applied: α = [1e-1, 1e-2, 1] for the synthetic dataset, α = [1e -2, 1e -3, 2] for the MNIST dataset, and α = [1e -1, 1e -2, 1] for the phenotype dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G ALGORITHM PSEUDOCODE</head><p>The pseudocode for the proposed algorithm is presented in Algorithm 1.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Multimodal data with causal latent variables.</figDesc><graphic coords="2,108.00,350.18,142.56,140.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>i , and allow for flexible causal relationships among latent components from potentially different modalities, such that z</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>&amp; Invertibility]: The generating functions g x (m) and g(m) are smooth and have smooth inverse functions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Denser graph Ĝ.</figDesc><graphic coords="6,373.61,565.60,130.40,88.49" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Estimation framework. Given multimodal observations (x (1) , . . . , x (M ) ), the latent variables and domain-specific information in modality m are inferred as ẑ(m) and η(m) by individual encoders. The observations are then reconstructed with corresponding decoders as x(m) . We enforce independence conditions by minimizing the KL divergence term D KL [{η (m) } M m=1 , {ε i }</figDesc><graphic coords="8,111.67,144.17,158.40,105.43" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>a single modality. (3) Multimodal contrastive learning (MCL) (Daunhawer et al., 2023), which recovers the shared latent factors from multiple modalities. Throughout the experiments, we consider the following evaluation metrics: (1) Mean Correlation Coefficient (MCC) measures how well the estimated latent variables match the true ones, with an MCC of 1 indicating perfect identifiability up to component-wise transformations. (2) R2 measures the proportion of variance in the ground truth latent that is explained by the estimated latent, with a value of 1 indicating that all variance is explained. (3) Structural Hamming Distance (SHD) compares graphs by their adjacency matrices, where a lower SHD indicates stronger similarity between graphs.(a) Causal comparison between estimated and true graphs (SHD=0). (b) Comparison of the identifiability result in different cases. (c) Identifiability result under different sparsity ratios.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Numerical experiment results. (a) Successful recovery of the inter-modal causal graph. (b) Baseline comparisons in different cases. (c) Result of sparsity ablation study.</figDesc><graphic coords="9,110.49,182.72,142.55,71.27" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>6. 3</head><label>3</label><figDesc>REAL-WORLD DATASET: HUMAN PHENOTYPEThe human phenotype dataset<ref type="bibr" target="#b61">(Shilo et al., 2021</ref>) is a large-scale, longitudinal collection of phenotypic profiles from a diverse global population. It includes comprehensive human health data and provides a comprehensive view of health and disease factors. The dataset contains various types of participant information, categorized into tabular, time series, and image data. Specifically, it includes health information across 30 modalities, such as blood tests, anthropometry, fundus imaging, etc. Detailed data descriptions can be found in the Appendix D.3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Causal analysis results across different modalities, including hand grip, medical conditions, sleep, and anthropometrics. We ran the causal algorithm on all variables, but for clarity only report the causal relationships that have direct connections to the estimated latent variables.</figDesc><graphic coords="10,146.35,278.70,316.80,103.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>) to derive the relation between the estimated graph structures and true graph structures encoded in G ∂ẑ ∂ẑ and G ∂z ∂z respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>) Therefore, we have shown that T ∂ ε ∂z is block-diagonal w.r.t. the groups. This structure allows us to simplify Eq. (20) to directly characterize the relation between the two graphical structures G ∂ẑ ∂ẑ and G ∂z ∂z . In particular, since T ∂ ε ∂z is block-diagonal and T ∂ẑ ∂ ε is diagonal, the off-diagonal blocks on the left-hand side of Eq. (20) are determined by G ∂ẑ ∂ẑ</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>Expressing the block [(m ∩ n), (m \ n)] on the left-hand side of Eq. (32) gives:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>m∩n),(m\n) = T ∂ẑ ∂z (m∩n),: G ∂z ∂z :,(m\n) = T ∂ẑ ∂z (m∩n),(m∩n) G ∂z ∂z (m∩n),(m\n) . (34) Thus, we have the equality for the block [(m ∩ n), (m \ n)]:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head></head><label></label><figDesc>Specifically, we classify the blocks in the estimation graph Ĝ ∂ẑ ∂ẑ into the following categories for two distinct atomic blocks b 1 and b 2 . Region 1 : Blocks b 1 and b 2 do not have nested memberships, i.e., M(z (b1) ) ̸ ⊂ M(z (b2) ) and M(z (b2) ) ̸ ⊂ M(z (b1) ); Region 2 : Block b 1 has fewer memberships than block b 2 : z (b1) ≺ z (b2) ; Region 3 : Block b 1 has more memberships than block b 2 : z (b2) ≺ z (b1) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head></head><label></label><figDesc>2) will engage the product T ∂ẑ ∂ ε T ∂ ε ∂z in Eq. (31) in addition to the sparsity in the estimated graph G ∂ẑ ∂ẑ . Overall conditions. Consolidating all the considerations above, we re-define objects in Condition 4.3 as follows. 1. The indeterminacy matrix T := T on + T off is not strictly block-diagonal: The matrix T on contains all the on-diagonal square invertible matrices T on := diag(T b1 , . . . , T b |B| ) and T off contains all the off-diagonal elements potentially nonzero in the regions (b, H(b) \ b) for b ∈ B. Also, the matrix multiplication becomes T ∂ẑ ∂z ( b),H( b) sub-matrices on which we impose the sparsity controls are exactly the union of Region 2 and Region 1, i.e., the complement of Region 3. We denote such a region as the function of the block index (E(b), b) for each b ∈ B.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head></head><label></label><figDesc>(a) for clarity. D.3 REAL-WORLD DATASET In this paper, we consider three types of datasets, including image, time series, and tabular data. Visualizations of the image and time-series datasets are shown in Figure 7 (b-c).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Visualization on the datasets: (a) Synthetic dataset: Variant MNIST. (b) Real-world dataset: Fundus imaging shows the interior surface of the eyes. (c) Real-world dataset: Sleep monitoring shows the time-series recording of sleep-related metrics overnight.</figDesc><graphic coords="28,116.66,214.79,376.20,147.18" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: (a) Comparison of loss across different latent dimensions. (b) The effect of sample size.</figDesc><graphic coords="30,172.71,306.78,122.17,99.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Related work on multimodal causal representation learning. This table considers whether a method can accommodate more than two modalities, whether the latent variable distribution is nonparametric, whether it allows dependency among latent variables, and whether identifiability is component-wise.</figDesc><table><row><cell>Related work</cell><cell cols="4">&gt; 2 Modalities Nonparam. Dist. Latent Dependency Component-wise Iden.</cell></row><row><cell>Gresele et al. (2020)</cell><cell>✓</cell><cell>×</cell><cell>×</cell><cell>✓</cell></row><row><cell>Von Kügelgen et al. (2021)</cell><cell>×</cell><cell>✓</cell><cell>✓</cell><cell>×</cell></row><row><cell>Daunhawer et al. (2023)</cell><cell>×</cell><cell>✓</cell><cell>✓</cell><cell>×</cell></row><row><cell>Yao et al. (2023)</cell><cell>✓</cell><cell>✓</cell><cell>✓</cell><cell>×</cell></row><row><cell>Morioka &amp; Hyvarinen (2024)</cell><cell>✓</cell><cell>×</cell><cell>✓</cell><cell>✓</cell></row><row><cell>Our work</cell><cell>✓</cell><cell>✓</cell><cell>✓</cell><cell>✓</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Discussion on the conditions. Condition 4.3 stipulates sparse cross-modality causal connections among latent components z. Under this condition, if a latent component ẑ(m)</figDesc><table><row><cell></cell><cell>i</cell><cell>is a function of two</cell></row><row><cell>components</cell><cell>ẑ(m)</cell></row></table><note><p>j and ẑ(m) k</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>The results of MNIST dataset.MCL BetaVAE CausalVAE OursR2 0.79 ± 6e-5 0.68 ± 2e-3 0.50 ± 4e-3 0.90 ± 9e-5 MCC 0.63 ± 2e-6 0.53 ± 1e-3 0.74 ± 2e-3 0.85 ± 3e-5Results. Table2presents the results of the identifiability comparison, where higher MCC and R2 indicate better performance of our method. BetaVAE does not explicitly model causal relationships among latent variables, leading to suboptimal recovery in our setting. CausalVAE, which relies on additional supervision, fails to recover the latent variables effectively.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Proof for Theorem 4.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20 C.2 Proof for Theorem 4.4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21 C.3 Extended Theorem 4.2 and its Proof . . . . . . . . . . . . . . . . . . . . . . . . . 23 C.4 Extended Theorem 4.4 and its Proof . . . . . . . . . . . . . . . . . . . . . . . . . 24We summarize the notations used throughout the paper in Table3.</figDesc><table><row><cell cols="2">Supplementary Materials for "Causal Representation Learning A NOTATION AND TERMINOLOGY</cell></row><row><cell>from Multimodal Biomedical Observations"</cell><cell></cell></row><row><cell>CONTENTS Index</cell><cell></cell></row><row><cell>A Notation and Terminology m, n Modality index i, j Variable element index</cell><cell>18</cell></row><row><cell>B Constraints in the Estimation Framework I(•) Component indices of a given argument d(•) Dimensionality indices of a given argument</cell><cell>18</cell></row><row><cell>C Identifiability Theory Variable C.1 D Experimental Details x (m)</cell><cell>20 27</cell></row><row><cell>E Extended Experiment</cell><cell>29</cell></row><row><cell>F Implementation Details</cell><cell>30</cell></row><row><cell>G Algorithm Pseudocode</cell><cell>31</cell></row></table><note><p>D.1 Numerical Dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27 D.2 Synthetic Dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27 D.3 Real-world Dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 D.4 Evaluation Metrics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 D.5 Detailed Discussion on Human Phenotype . . . . . . . . . . . . . . . . . . . . . . 29 F.1 Network Architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31 F.2 Training Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Recon , α Ind , α Sp Weights in the combination objective List of notations.</figDesc><table><row><cell></cell><cell></cell><cell>specific latent variables in modality m, and the rest of others</cell></row><row><cell>η</cell><cell></cell><cell>Domain-specific information</cell></row><row><cell>ϵ</cell><cell></cell><cell>Mutually independent exogenous variables</cell></row><row><cell>ẑi</cell><cell></cell><cell>Estimated latent variables over z i</cell></row><row><cell>x(m)</cell><cell></cell><cell>Reconstructed observation in modality m</cell></row><row><cell>Pa(z i (m)</cell><cell>)</cell><cell>(m) i Set of direct cause nodes/parents of variable z</cell></row><row><cell cols="3">Function and Hyperparameter</cell></row><row><cell>g z m</cell><cell></cell><cell></cell></row></table><note><p>i Causal function among latent variables g x (m) Nonparametric mixing function in modality m h Invertible mapping from true latent to the estimated latent p Distribution function (e.g., p zi is the distribution of z i ) α</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Sleep monitoring is a time-series dataset collected over three consecutive nights that records various metrics including sleep stage, body position, respiratory events, heart rate, oxygen saturation, and snoring. This dataset focuses on obstructive sleep apnea (OSA), a sleep disorder in which a person's breathing is interrupted during sleep due to the relaxation of throat muscles, causing upper airway obstruction. These interruptions often lead to loud snoring, reduced blood oxygen levels, stress responses, awakenings, and fragmented sleep.</figDesc><table><row><cell>This dataset is collected from a Home Sleep Apnea Test (HSAT), a non-invasive diagnostic method</cell></row><row><cell>for sleep apnea. Patients wear a portable device overnight to monitor their breathing patterns, heart</cell></row><row><cell>rate, oxygen levels, snoring, and other sleep patterns. The dataset includes multiple channels, such as</cell></row><row><cell>ACTIGRAPH for movement, HEARTRATE DIST for heart rate, SPO2 WRIST for blood oxygen</cell></row><row><cell>saturation, and SBORE WP for snoring, capturing key aspects of physical activity and sleep patterns</cell></row><row><cell>during the HSAT. The device calculates apnea-related indices, including the Apnea/Hypopnea Index</cell></row><row><cell>(AHI), Respiratory Disturbance Index (RDI), and Oxygen Desaturation Index (ODI), as well as</cell></row><row><cell>indices for diagnosing conditions such as atrial fibrillation.</cell></row><row><cell>D.4 EVALUATION METRICS</cell></row></table><note><p>MCC: Mean Correlation Coefficient MCC is a standard metric used to evaluate the recovery of latent factors in causal representation learning. It measures the alignment between the ground-truth</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Extended experiment results across different experimental settings.</figDesc><table><row><cell>Metric</cell><cell cols="2">Complex Scenarios</cell><cell cols="2">Non-DAG Settings</cell><cell cols="2">Shared Latent Variables</cell></row><row><cell></cell><cell cols="6">Five mods Six mods Eight mods Cyclic within Cyclic across Two mods Three mods</cell></row><row><cell>R2</cell><cell>0.89± 1e-4 0.97± 8e-7</cell><cell>0.83± 1e-3</cell><cell>0.95± 1e-5</cell><cell>0.94± 2e-4</cell><cell>0.86± 5e-4</cell><cell>0.90± 1e-4</cell></row><row><cell>MCC</cell><cell>0.84± 3e-4 0.82± 4e-4</cell><cell>0.91± 5e-4</cell><cell>0.89± 2e-4</cell><cell>0.92± 1e-5</cell><cell>0.83±± 7e-4</cell><cell>0.83± 4e-6</cell></row><row><cell cols="3">F.1 NETWORK ARCHITECTURE</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Please see Appendix A for details on the notion of identifiability.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>We use • to differentiate η(-m) from a collection of modality-specific variables η defined in Eq. (2).</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Additional notations. We slightly abuse the notation to denote both sets and vectors with bold symbols z. Let z (m∩n) be the set of latent components shared by modality m and n, i.e., z (m∩n) := z (m) ∩ z (n) . Analogously, let z (m\n) be the set of latent components in modality m that are not shared by n, i.e., z (m\n) := z (m) \ z (n) . Theorem C.7 (Generalized Subspace Identifiability). Let {(g x (m) , gx (-m) )} M m=1 and {(ĝ x (m) , ĝx (-m) )} M m=1 be two specifications of the generating process Eq. (3) with potentially shared variables z (m∩n) over any two modalities m and n. Suppose that they both match the observational distribution p(x) = p(x) and satisfy Condition 4.1. Then any subspace ẑ(m) , shared subspace ẑ(m∩n) and their counterparts z (m) , z (m∩n) are equivalent up to invertible maps.</p><p>Proof. We note that the latent model with shared latent variables across modalities can still be cast into Equation (3) and satisfies Condition 4.1. As a consequence, Theorem 4.2 gives us the subspace identification for each modality as in the disjoint case. Moreover, we can identify any blocks among modalities thanks to Theorem C.5. This concludes the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.4 EXTENDED THEOREM 4.4 AND ITS PROOF</head><p>Additional notations and discussion. The participation of multiple modalities requires a new definition of the shared blocks in z since the sharing structure could be nested and various numbers of modalities could share one partition. We partition the entire latent space z into disjoint blocks {z (b) } b∈B , whose components z have exactly the same modality membership M(z) := {m ∈ [M ] : z ∈ z (m) }. We define the z H(b) as the smallest (the least components) identified block in z that contains z (b) . In the two-modal case, we have b1) is shared by a strict subset of modalities that share z (b2) , i.e., M(z (b1) ) ⊊ M(z (b2) ). Therefore, we have either z b) (it is not identifiable by itself but belongs to an identifiable block z H(b) together with a more deeply shared block z H(b) \ z (b) ). We denote former blocks as b + ∈ B + , i.e., z H(b + ) = z (b + ) , and the latter blocks as b -∈ B -= B \ B + . In the two-modal case, the modal-specific blocks z (m\n) , z (n\m) are not identifiable themselves, and we have z (m\n) ≺ z (m∩n) and z (n\m) ≺ z (m∩n) , and</p><p>We note that all shared blocks z (b + ) are identified. Thus their bijective indeterminacies are w.r.t, themselves, i.e., z (b + ) → ẑ(b + ) , which implies the square shape of their indeterminacy matrices [T ∂ẑ ∂z ] (b + ),(b + ) . In contrast, the unidentifiable blocks ẑ(b -) can potentially receive the influence from all other blocks in its minimal block z H(b -) . However,</p><p>. For instance, ẑ(m\n) may receive influences from z (m∩n) and z (m\n) . Consequently, their associated non-trivial indeterminacy matrices are</p><p>). Thus, the indeterminacy matrix T can be expressed as T := T on + T off , where The matrix T on contains all the on-diagonal square invertible matrices T on := diag(T 1 on , . . . , T</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(|B|) on</head><p>) and T off contains all the off-diagonal elements potentially nonzero in the regions (b, H(b) \ b) for b ∈ B. We denote this class of matrix T as T . We denote a set of blocks E(b) whose memberships are either a strict superset or do not nest with b's membership  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">the National Institutes of Health (NIH) under Contract R01HL159805, and grants from Quris AI, Florin Court Capital, and MBZUAI-WIS Joint Program. The work of L. Kong is supported in part by NSF DMS-2134080 through an award to Y. Chi. P. Stojanov was supported in part by the National Cancer Institute (NCI) grant number: K99CA277583-01</title>
		<idno>NSF Award No. 2229881</idno>
		<imprint/>
		<respStmt>
			<orgName>AI Institute for Societal Decision Making (AI-SDM</orgName>
		</respStmt>
	</monogr>
	<note>Wendy Schmidt Center at the Broad Institute of MIT and Harvard. BIBLIOGRAPHY</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Interventional causal representation learning</title>
		<author>
			<persName><forename type="first">Kartik</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Divyat</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="372" to="407" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Martin</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ishaan</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.02893</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">Invariant risk minimization. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Structure and evolution of transcriptional regulatory networks</title>
		<author>
			<persName><forename type="first">Nicholas</forename><forename type="middle">M</forename><surname>Madan Babu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Luscombe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Aravind</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sarah</forename><forename type="middle">A</forename><surname>Gerstein</surname></persName>
		</author>
		<author>
			<persName><surname>Teichmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current opinion in structural biology</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="283" to="291" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Size and form in efficient transportation networks</title>
		<author>
			<persName><forename type="first">Amos</forename><surname>Jayanth R Banavar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Maritan</surname></persName>
		</author>
		<author>
			<persName><surname>Rinaldo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">399</biblScope>
			<biblScope unit="issue">6732</biblScope>
			<biblScope unit="page" from="130" to="132" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Hand grip strength and ocular associations: the ural eye and medical study</title>
		<author>
			<persName><surname>Mukharram M Bikbov</surname></persName>
		</author>
		<author>
			<persName><surname>Rinat M Zainullin</surname></persName>
		</author>
		<author>
			<persName><surname>Timur R Gilmanshin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ellina</surname></persName>
		</author>
		<author>
			<persName><surname>Iakupova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gyulli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Songhomitra</forename><surname>Kazakbaeva</surname></persName>
		</author>
		<author>
			<persName><surname>Panda-Jonas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Azaliia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albina</forename><forename type="middle">A</forename><surname>Tuliakova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leisan</forename><forename type="middle">I</forename><surname>Fakhretdinova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jost B</forename><surname>Gilemzianova</surname></persName>
		</author>
		<author>
			<persName><surname>Jonas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">British Journal of Ophthalmology</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1567" to="1574" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning linear causal representations from interventions under general nonlinear mixing</title>
		<author>
			<persName><forename type="first">Simon</forename><surname>Buchholz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Goutham</forename><surname>Rajendran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elan</forename><surname>Rosenfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bryon</forename><surname>Aragam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pradeep</forename><surname>Ravikumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Explorability and the origin of network sparsity in living systems</title>
		<author>
			<persName><forename type="first">Samir</forename><surname>Daniel M Busiello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jorge</forename><surname>Suweis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amos</forename><surname>Hidalgo</surname></persName>
		</author>
		<author>
			<persName><surname>Maritan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific reports</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">12323</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">An rna foundation model enables discovery of disease mechanisms and candidate therapeutics</title>
		<author>
			<persName><forename type="first">Albi</forename><surname>Celaj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alice</forename><forename type="middle">Jiexin</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">Y</forename><surname>Tammy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erle</forename><forename type="middle">M</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alston</forename><surname>Holgersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Varun</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><surname>Lodaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">E</forename><surname>Christopher B Cole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carl</forename><surname>Denroche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omar</forename><surname>Spickett</surname></persName>
		</author>
		<author>
			<persName><surname>Wagih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">bioRxiv</title>
		<imprint>
			<biblScope unit="page" from="2023" to="2029" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Self-supervised learning on millions of pre-mrna sequences improves sequence-based rna splicing prediction</title>
		<author>
			<persName><forename type="first">Ken</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maolin</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhixiang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuedong</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">bioRxiv</title>
		<imprint>
			<biblScope unit="page" from="2023" to="2024" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Independent component analysis, a new concept</title>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Comon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal processing</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="287" to="314" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The nucleotide transformer: Building and evaluating robust foundation models for human genomics</title>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Dalla-Torre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liam</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Javier</forename><surname>Mendoza Revilla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><forename type="middle">Lopez</forename><surname>Carranza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Henryk Grzywaczewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Oteri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Dallago</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evan</forename><surname>Trop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hassan</forename><surname>Sirelkhatim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcin</forename><surname>Skwark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karim</forename><surname>Beguir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Pierrot</surname></persName>
		</author>
		<idno type="DOI">10.1101/2023.01.11.523679</idno>
		<ptr target="https://www.biorxiv.org/content/early/2023/01/15/2023.01.11.523679" />
	</analytic>
	<monogr>
		<title level="j">bioRxiv</title>
		<imprint>
			<biblScope unit="page">2023</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Identifiability results for multimodal contrastive learning</title>
		<author>
			<persName><forename type="first">Imant</forename><surname>Daunhawer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alice</forename><surname>Bizeul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emanuele</forename><surname>Palumbo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Marx</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julia</forename><forename type="middle">E</forename><surname>Vogt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Applying biobert to extract germline gene-disease associations for building a knowledge graph from the biomedical literature</title>
		<author>
			<persName><forename type="first">Armando D Diaz</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><forename type="middle">S</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Songhui</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sean</forename><forename type="middle">T</forename><surname>Hayes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2023 7th International Conference on Information System and Data Mining</title>
		<meeting>the 2023 7th International Conference on Information System and Data Mining</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="37" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The relationship between age and colour content in fundus images</title>
		<author>
			<persName><forename type="first">Ole</forename><forename type="middle">K</forename><surname>Bernhard M Ege</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ole</forename><forename type="middle">V</forename><surname>Hejlesen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toke</forename><surname>Larsen</surname></persName>
		</author>
		<author>
			<persName><surname>Bek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Ophthalmologica Scandinavica</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="485" to="489" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Changes in fundus autofluorescence in patients with age-related maculopathy. correlation to visual function: a prospective study. Graefe&apos;s Archive for</title>
		<author>
			<persName><forename type="first">Wilma</forename><surname>Einbock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Moessner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ute</forename><forename type="middle">Ek</forename><surname>Schnurrbusch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><forename type="middle">G</forename><surname>Holz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Group</forename><surname>Study</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Clinical and Experimental Ophthalmology</title>
		<imprint>
			<biblScope unit="volume">243</biblScope>
			<biblScope unit="page" from="300" to="305" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Leveraging sparse and shared feature activations for disentangled representation learning</title>
		<author>
			<persName><forename type="first">Marco</forename><surname>Fumero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Wenzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename><surname>Zancato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Achille</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emanuele</forename><surname>Rodolà</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Soatto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Locatello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="27682" to="27698" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Multi-modal transfer learning between biological foundation models</title>
		<author>
			<persName><forename type="first">Juan</forename><surname>Jose Garau-Luis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liam</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Masa</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernardo</forename><forename type="middle">P</forename><surname>De Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lorenz</forename><surname>Hexemer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Laurent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Grzegorzewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maren</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Pierrot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Richard</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2406.14150" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The incomplete rosetta stone problem: Identifiability results for multi-view nonlinear ica</title>
		<author>
			<persName><forename type="first">Luigi</forename><surname>Gresele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arash</forename><surname>Paul K Rubenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Mehrjou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Locatello</surname></persName>
		</author>
		<author>
			<persName><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Uncertainty in Artificial Intelligence</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="217" to="227" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Evaluation and mitigation of the limitations of large language models in clinical decision-making</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Hager</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Friederike</forename><surname>Jungmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robbie</forename><surname>Holland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kunal</forename><surname>Bhagat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Inga</forename><surname>Hubrecht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manuel</forename><surname>Knauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Vielhauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcus</forename><surname>Makowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rickmer</forename><surname>Braren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georgios</forename><surname>Kaissis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature medicine</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2613" to="2622" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">beta-vae: Learning basic visual concepts with a constrained variational framework</title>
		<author>
			<persName><forename type="first">Irina</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Loic</forename><surname>Matthey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arka</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Burgess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">M</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shakir</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><surname>Lerchner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR</title>
		<imprint>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Neural autoregressive flows</title>
		<author>
			<persName><forename type="first">Chin-Wei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Lacoste</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2078" to="2087" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Unsupervised feature extraction by time-contrastive learning and nonlinear ica</title>
		<author>
			<persName><forename type="first">Aapo</forename><surname>Hyvarinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hiroshi</forename><surname>Morioka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Nonlinear ica using auxiliary variables and generalized contrastive learning</title>
		<author>
			<persName><forename type="first">Aapo</forename><surname>Hyvarinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hiroaki</forename><surname>Sasaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Turner</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">The 22nd International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="859" to="868" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">A disease-specific foundation model using over 100k fundus images: Release and validation for abnormality and multi-disease classification on downstream tasks</title>
		<author>
			<persName><forename type="first">Boa</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youngbin</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eun</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Kyung</forename><surname>Choe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chang</forename><surname>Ki Yoon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyuk</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Young-Gon</forename><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2408.08790</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning nonparametric latent causal graphs with unknown interventions</title>
		<author>
			<persName><forename type="first">Yibo</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bryon</forename><surname>Aragam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="60468" to="60513" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Highly accurate protein structure prediction with alphafold</title>
		<author>
			<persName><forename type="first">John</forename><surname>Jumper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Pritzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Figurnov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olaf</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kathryn</forename><surname>Tunyasuvunakool</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Russ</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Augustin</forename><surname>Žídek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Potapenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">nature</title>
		<imprint>
			<biblScope unit="volume">596</biblScope>
			<biblScope unit="issue">7873</biblScope>
			<biblScope unit="page" from="583" to="589" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Variational autoencoders and nonlinear ica: A unifying framework</title>
		<author>
			<persName><forename type="first">Ilyes</forename><surname>Khemakhem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ricardo</forename><surname>Monti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aapo</forename><surname>Hyvarinen</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on artificial intelligence and statistics</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2207" to="2217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Ice-beem: Identifiable conditional energy-based deep models based on nonlinear ica</title>
		<author>
			<persName><forename type="first">Ilyes</forename><surname>Khemakhem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ricardo</forename><surname>Monti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Diederik Kingma, and Aapo Hyvarinen</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="12768" to="12778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Supervised contrastive learning</title>
		<author>
			<persName><forename type="first">Prannay</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Teterwak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Sarna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonglong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Maschinot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ce</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dilip</forename><surname>Krishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="18661" to="18673" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Normalizing flows: An introduction and review of current methods</title>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Kobyzev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon Jd</forename><surname>Prince</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcus</forename><forename type="middle">A</forename><surname>Brubaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="3964" to="3979" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">Lingjing</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoan</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weiran</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujia</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guangyi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Petar</forename><surname>Stojanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Akinwande</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.06510</idno>
		<title level="m">Partial identifiability for domain adaptation</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Synergies between disentanglement and sparsity: Generalization and identifiability in multi-task learning</title>
		<author>
			<persName><forename type="first">Sébastien</forename><surname>Lachapelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tristan</forename><surname>Deleu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Divyat</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ioannis</forename><surname>Mitliagkas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Lacoste-Julien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quentin</forename><surname>Bertrand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="18171" to="18206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">Sébastien</forename><surname>Lachapelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rodríguez</forename><surname>Pau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yash</forename><surname>López</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katie</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rémi</forename><surname>Everett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Le Priol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Lacoste</surname></persName>
		</author>
		<author>
			<persName><surname>Lacoste-Julien</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2401.04890</idno>
		<title level="m">Nonparametric partial disentanglement via mechanism sparsity: Sparse actions, interventions and sparse temporal dependencies</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<ptr target="http://yann.lecun.com/exdb/mnist/" />
		<title level="m">The mnist database of handwritten digits</title>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Genome-wide association studies and polygenic risk score phenome-wide association studies across complex phenotypes in the human phenotype project</title>
		<author>
			<persName><forename type="first">Zachary</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iris</forename><surname>Kalka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dmitry</forename><surname>Kolobkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hagai</forename><surname>Rossman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anastasia</forename><surname>Godneva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Smadar</forename><surname>Shilo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ayya</forename><surname>Keshet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daphna</forename><surname>Weissglas-Volkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tal</forename><surname>Shor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alon</forename><surname>Diament</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="90" to="101" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">On causal discovery in the presence of deterministic relations</title>
		<author>
			<persName><forename type="first">Loka</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoyue</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanin</forename><surname>Al Ghothani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Biwei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiji</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shahar</forename><surname>Harel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isaac</forename><surname>Bentwich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guangyi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Thirty-eighth Annual Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<author>
			<persName><forename type="first">Loka</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ignavier</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gongxu</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Biwei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guangyi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tongliang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.13241</idno>
		<title level="m">Federated causal discovery from heterogeneous data</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Codonbert: Large language models for mrna design and optimization</title>
		<author>
			<persName><forename type="first">Sizhen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saeed</forename><surname>Moayedpour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruijiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saleh</forename><surname>Riahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lorenzo</forename><surname>Kogler-Anele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Milad</forename><surname>Miladi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Miner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dinghai</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">bioRxiv</title>
		<imprint>
			<biblScope unit="page" from="2023" to="2029" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Causal representation learning via counterfactual intervention</title>
		<author>
			<persName><forename type="first">Xiutian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siqi</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="3234" to="3242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Evolutionary-scale prediction of atomic-level protein structure with a language model</title>
		<author>
			<persName><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Halil</forename><surname>Akin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roshan</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Hie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhongkai</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenting</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikita</forename><surname>Smetanin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Verkuil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ori</forename><surname>Kabeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaniv</forename><surname>Shmueli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">379</biblScope>
			<biblScope unit="issue">6637</biblScope>
			<biblScope unit="page" from="1123" to="1130" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Controllability of complex networks</title>
		<author>
			<persName><forename type="first">Yang-Yu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean-Jacques</forename><surname>Slotine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albert-László</forename><surname>Barabási</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">nature</title>
		<imprint>
			<biblScope unit="volume">473</biblScope>
			<biblScope unit="issue">7346</biblScope>
			<biblScope unit="page" from="167" to="173" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<author>
			<persName><forename type="first">Gongxu</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoyue</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boyang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Loka</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Biwei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Petar</forename><surname>Stojanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2501.10124</idno>
		<title level="m">Gene regulatory network inference in the presence of selection bias and latent confounders</title>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Multimodality representation learning: A survey on evolution, pretraining and its applications</title>
		<author>
			<persName><forename type="first">Sarah</forename><surname>Muhammad Arslan Manzoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziting</forename><surname>Albarri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zaiqiao</forename><surname>Xian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Preslav</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shangsong</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Multimedia Computing, Communications and Applications</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="34" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Towards cross-modal causal structure and representation learning</title>
		<author>
			<persName><forename type="first">Haiyi</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongfu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><forename type="middle">Xiaotian</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Panayiotis</forename><forename type="middle">V</forename><surname>Benos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning for Health</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="120" to="140" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Network motifs: simple building blocks of complex networks</title>
		<author>
			<persName><forename type="first">Ron</forename><surname>Milo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shai</forename><surname>Shen-Orr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shalev</forename><surname>Itzkovitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nadav</forename><surname>Kashtan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dmitri</forename><surname>Chklovskii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Uri</forename><surname>Alon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">298</biblScope>
			<biblScope unit="issue">5594</biblScope>
			<biblScope unit="page" from="824" to="827" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Identifiable deep generative models via sparse decoding</title>
		<author>
			<persName><forename type="first">D</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sridhar</surname></persName>
		</author>
		<author>
			<persName><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions on machine learning research</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Connectivity-contrastive learning: Combining causal discovery and representation learning for multimodal data</title>
		<author>
			<persName><forename type="first">Hiroshi</forename><surname>Morioka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aapo</forename><surname>Hyvarinen</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on artificial intelligence and statistics</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="3399" to="3426" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Causal representation learning made identifiable by grouping of observational variables</title>
		<author>
			<persName><forename type="first">Hiroshi</forename><surname>Morioka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aapo</forename><surname>Hyvarinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Forty-first International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Structural controllability of unidirectional bipartite networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Jose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tatsuya</forename><surname>Nacher</surname></persName>
		</author>
		<author>
			<persName><surname>Akutsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific reports</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">1647</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<author>
			<persName><forename type="first">Eric</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Poli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marjan</forename><surname>Faizi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armin</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Callum</forename><surname>Birch-Sykes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Wornow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aman</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clayton</forename><surname>Rabideau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Massaroli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><forename type="middle">A</forename><surname>Baccus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Ré</surname></persName>
		</author>
		<author>
			<persName><surname>Hyenadna</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2306.15794" />
		<title level="m">Long-range genomic sequence modeling at single nucleotide resolution</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Sequence modeling and design from molecular to genome scale with evo</title>
		<author>
			<persName><forename type="first">Eric</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Poli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armin</forename><forename type="middle">W</forename><surname>Matthew G Durrant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeremy</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Madelena</forename><forename type="middle">Y</forename><surname>Sullivan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashley</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aman</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><surname>Lou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BioRxiv</title>
		<imprint>
			<biblScope unit="page" from="2024" to="2026" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A hybrid causal search algorithm for latent variable models</title>
		<author>
			<persName><forename type="first">Juan</forename><surname>Miguel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ogarrio</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Spirtes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joe</forename><surname>Ramsey</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Conference on probabilistic graphical models</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="368" to="379" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yazhe</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.03748</idno>
		<title level="m">Representation learning with contrastive predictive coding</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Chatgpt or llm in next-generation drug discovery and development: pharmaceutical and biotechnology companies can make use of the artificial intelligence-based device for a faster way of drug discovery and development</title>
		<author>
			<persName><forename type="first">Soumen</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manojit</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Md Aminul</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chiranjib</forename><surname>Chakraborty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Surgery</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="4382" to="4384" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<author>
			<persName><forename type="first">Qizhi</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lijun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaiyuan</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaozhuan</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yin</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinhua</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shufang</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.17810</idno>
	</analytic>
	<monogr>
		<title level="m">Towards generalized biological understanding with iupac integration and multi-task tuning</title>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="volume">5</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Determinant factors of intraocular pressure responses to a maximal isometric handgrip test: hand dominance, handgrip strength and sex</title>
		<author>
			<persName><forename type="first">Alejandro</forename><surname>Pérez-Castilla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amador</forename><surname>García-Ramos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Beatríz</forename><surname>Redondo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fernández-Revelles</forename><surname>Andrés</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raimundo</forename><surname>Jiménez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jesús</forename><surname>Vera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current Eye Research</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="64" to="70" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Associations of grip strength with retinal and choroidal thickness in patients with type 2 diabetes mellitus without retinopathy: a cross-sectional study</title>
		<author>
			<persName><forename type="first">Zihan</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miao</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Langhua</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuting</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xia</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenyong</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMJ open</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">36782</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Learning transferable visual models from natural language supervision</title>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jong</forename><forename type="middle">Wook</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Hallacy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pamela</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="8748" to="8763" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">An integrated multimodal model of alcohol use disorder generated by data-driven causal discovery analysis</title>
		<author>
			<persName><forename type="first">Eric</forename><surname>Rawls</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erich</forename><surname>Kummerfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Zilverstand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications biology</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">435</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Toward causal representation learning</title>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Locatello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><forename type="middle">Rosemary</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anirudh</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="612" to="634" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">10 k: a large-scale prospective longitudinal study in israel</title>
		<author>
			<persName><forename type="first">Smadar</forename><surname>Shilo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Bar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ayya</forename><surname>Keshet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yeela</forename><surname>Talmor-Barkan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hagai</forename><surname>Rossman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anastasia</forename><surname>Godneva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaron</forename><surname>Aviv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yochai</forename><surname>Edlitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lee</forename><surname>Reicher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dmitry</forename><surname>Kolobkov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European journal of epidemiology</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1187" to="1194" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Rna language models predict mutations that improve rna function</title>
		<author>
			<persName><forename type="first">Yekaterina</forename><surname>Shulgina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marena</forename><forename type="middle">I</forename><surname>Trinidad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Conner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hunter</forename><surname>Langeberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seyone</forename><surname>Nisonoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Petr</forename><surname>Chithrananda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amos</forename><forename type="middle">J</forename><surname>Skopintsev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaymin</forename><surname>Nissley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ron</forename><forename type="middle">S</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Honglue</forename><surname>Boger</surname></persName>
		</author>
		<author>
			<persName><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">bioRxiv</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Cataract surgery and iop</title>
		<author>
			<persName><forename type="first">P</forename><surname>Slabaugh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Glaucoma</forename><surname>Smit</surname></persName>
		</author>
		<author>
			<persName><surname>Today</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>Glaucoma Today</publisher>
			<biblScope unit="page" from="17" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Causation, prediction, and search</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Spirtes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clark</forename><surname>Glymour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Scheines</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Unpaired multi-domain causal representation learning</title>
		<author>
			<persName><forename type="first">Nils</forename><surname>Sturma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chandler</forename><surname>Squires</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mathias</forename><surname>Drton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caroline</forename><surname>Uhler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Explainable multi-task learning for multimodality biological data analysis</title>
		<author>
			<persName><forename type="first">Xin</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yichun</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinhe</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zuwan</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Partarrieu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emma</forename><forename type="middle">Bou</forename><surname>Hanna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaolin</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuhong</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature communications</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">2546</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<author>
			<persName><forename type="first">Ross</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcin</forename><surname>Kardas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Scialom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Hartshorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elvis</forename><surname>Saravia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Poulton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Viktor</forename><surname>Kerkez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Stojnic</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2211.09085" />
		<title level="m">Galactica: A large language model for science</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">The wu-minn human connectome project: an overview</title>
		<author>
			<persName><forename type="first">Stephen</forename><forename type="middle">M</forename><surname>David C Van Essen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deanna</forename><forename type="middle">M</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><forename type="middle">Ej</forename><surname>Barch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Essa</forename><surname>Behrens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kamil</forename><surname>Yacoub</surname></persName>
		</author>
		<author>
			<persName><surname>Ugurbil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hcp</forename><surname>Wu-Minn</surname></persName>
		</author>
		<author>
			<persName><surname>Consortium</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="62" to="79" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Scorebased causal representation learning with interventions</title>
		<author>
			<persName><forename type="first">Burak</forename><surname>Varici</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emre</forename><surname>Acarturk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karthikeyan</forename><surname>Shanmugam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename><surname>Tajer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.08230</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Self-supervised learning with data augmentations provably isolates content from style</title>
		<author>
			<persName><forename type="first">Julius</forename><surname>Von Kügelgen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yash</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luigi</forename><surname>Gresele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wieland</forename><surname>Brendel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Besserve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Locatello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<editor>
			<persName><forename type="first">Michel</forename><surname>Julius Von Kügelgen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Liang</forename><surname>Besserve</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Luigi</forename><surname>Wendong</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Armin</forename><surname>Gresele</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Elias</forename><surname>Kekić</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">David</forename><surname>Bareinboim</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Bernhard</forename><surname>Blei</surname></persName>
		</editor>
		<editor>
			<persName><surname>Schölkopf</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="16451" to="16467" />
			<date type="published" when="2021">2021. 2023</date>
		</imprint>
	</monogr>
	<note>Advances in Neural Information Processing Systems</note>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">The correlation between oxygen saturation indices and the standard obstructive sleep apnea severity</title>
		<author>
			<persName><forename type="first">Omar</forename><surname>Siraj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bahaa</forename><surname>Wali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ibrahim</forename><surname>Abaalkhail</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Faris</forename><surname>Alqassas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">W</forename><surname>Alhejaili</surname></persName>
		</author>
		<author>
			<persName><surname>Spence</surname></persName>
		</author>
		<author>
			<persName><surname>Seithikurippu R Pandi-Perumal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of thoracic medicine</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="70" to="75" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Vlmixer: Unpaired vision-language pre-training via cross-modal cutmix</title>
		<author>
			<persName><forename type="first">Teng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenhao</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhichao</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Feng</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ran</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengguo</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="22680" to="22690" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Modelling universality and scaling</title>
		<author>
			<persName><forename type="first">Geoffrey B</forename><surname>West</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><forename type="middle">J</forename><surname>Enquist</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">H</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">420</biblScope>
			<biblScope unit="issue">6916</biblScope>
			<biblScope unit="page" from="626" to="627" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms</title>
		<author>
			<persName><forename type="first">Han</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kashif</forename><surname>Rasul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roland</forename><surname>Vollgraf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.07747</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<author>
			<persName><forename type="first">Danru</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dingling</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sébastien</forename><surname>Lachapelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Perouz</forename><surname>Taslakian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Julius Von Kügelgen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sara</forename><surname>Locatello</surname></persName>
		</author>
		<author>
			<persName><surname>Magliacane</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2403.08335</idno>
		<title level="m">A sparsity principle for partially observable causal representation learning</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<author>
			<persName><forename type="first">Mengyue</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Furui</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhitang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinwei</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianye</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><surname>Causalvae</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.08697</idno>
		<title level="m">Structured causal disentanglement in variational autoencoder</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title level="m" type="main">Multi-view causal representation learning with partial observability</title>
		<author>
			<persName><forename type="first">Dingling</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danru</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sébastien</forename><surname>Lachapelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sara</forename><surname>Magliacane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Perouz</forename><surname>Taslakian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georg</forename><surname>Martius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julius</forename><surname>Von Kügelgen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Locatello</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.04056</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title level="m" type="main">Learning temporally causal latent processes from general temporal data</title>
		<author>
			<persName><forename type="first">Weiran</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuewen</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changyin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.05428</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Biomedical generative pre-trained based transformer language model for age-related disease target discovery</title>
		<author>
			<persName><forename type="first">Diana</forename><surname>Zagirova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Pushkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Ho Duen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bonnie</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Man</forename><surname>Hei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anatoly</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denis</forename><surname>Urban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksandr</forename><surname>Sidorenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ekaterina</forename><surname>Kalashnikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Kozlova</surname></persName>
		</author>
		<author>
			<persName><surname>Naumov</surname></persName>
		</author>
		<author>
			<persName><surname>Frank W Pun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Aging (Albany NY)</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">18</biblScope>
			<biblScope unit="page">9293</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Multimodal intelligence: Representation learning, information fusion, and applications</title>
		<author>
			<persName><forename type="first">Chao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zichao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Selected Topics in Signal Processing</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="478" to="493" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Identifiability guarantees for causal disentanglement from soft interventions</title>
		<author>
			<persName><forename type="first">Jiaqi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristjan</forename><surname>Greenewald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chandler</forename><surname>Squires</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akash</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karthikeyan</forename><surname>Shanmugam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caroline</forename><surname>Uhler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
		<title level="m" type="main">Causal representation learning from multiple distributions: A general setting</title>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoan</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ignavier</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujia</forename><surname>Zheng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.05052</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title level="m" type="main">Multi-modal causal structure learning and root cause analysis</title>
		<author>
			<persName><forename type="first">Lecheng</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengzhang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingrui</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haifeng</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.02357</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title level="m" type="main">Large language models for scientific synthesis, inference and explanation</title>
		<author>
			<persName><forename type="first">Yizhen</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yee</forename><surname>Huan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaxin</forename><surname>Koh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anh</forename><forename type="middle">Tn</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lauren</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">I</forename><surname>May</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shirui</forename><surname>Webb</surname></persName>
		</author>
		<author>
			<persName><surname>Pan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.07984</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
		<title level="m" type="main">Large language models in drug discovery and development: From disease mechanisms to clinical trials</title>
		<author>
			<persName><forename type="first">Yizhen</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yee</forename><surname>Huan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maddie</forename><surname>Koh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lauren</forename><forename type="middle">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">I</forename><surname>May</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shirui</forename><surname>Webb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><surname>Church</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2409.04481</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Generalizing nonlinear ica beyond structural sparsity</title>
		<author>
			<persName><forename type="first">Yujia</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="13326" to="13355" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">On the identifiability of nonlinear ica: Sparsity and beyond</title>
		<author>
			<persName><forename type="first">Yujia</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ignavier</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="16411" to="16422" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">A foundation model for generalizable disease detection from retinal images</title>
		<author>
			<persName><forename type="first">Yukun</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">A</forename><surname>Chia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siegfried</forename><forename type="middle">K</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dominic</forename><forename type="middle">J</forename><surname>Murat S Ayhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robbert</forename><forename type="middle">R</forename><surname>Williamson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timing</forename><surname>Struyven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moucheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mateo</forename><forename type="middle">G</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Lozano</surname></persName>
		</author>
		<author>
			<persName><surname>Woodward-Court</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">622</biblScope>
			<biblScope unit="issue">7981</biblScope>
			<biblScope unit="page" from="156" to="163" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<title level="m" type="main">Dnabert-2: Efficient foundation model and benchmark for multi-species genome</title>
		<author>
			<persName><forename type="first">Zhihan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanrong</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weijian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pratik</forename><surname>Dutta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramana</forename><surname>Davuluri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Liu</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2306.15006" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Contrastive learning inverts the data generating process</title>
		<author>
			<persName><forename type="first">Yash</forename><surname>Roland S Zimmermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steffen</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wieland</forename><surname>Bethge</surname></persName>
		</author>
		<author>
			<persName><surname>Brendel</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="12979" to="12990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Output: Estimated latent variables ẑ(m) for each group m 10: for each group m = 1 to M do 11: Encode the current group latent and exogenous variables: ẑ(m) , η(m) = En (m) (x (m) ) 12: end for 13: Concatenate latent representations: {ẑ (m) } M m=1 = ẑ(1) ⊕ ẑ(2) ⊕ . . . ⊕ ẑ(M) 14: return Estimated latent variables and exogenous variables {ẑ (m) , η(m) } M m=1 15: 16: # Flow-based Noise Estimation 17: Input: Estimated latent variables for each group {ẑ (m) } M m=1 18: Output: Estimated noise term εd(z) i=1 19: Initialize adjacency Â 20: the parents of latent variable based on the adjacency matrix 21: Pass through flow model to obtain estimated residuals εi 22: Update the estimated causal graph based on the adjacency matrix with threshold 23: Compute sparsity loss based on L 1 norm 24: Compute the KL divergence between [{η (m) } M m=1</title>
		<author>
			<persName><forename type="first">Klea</forename><surname>Ziu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Slavomír</forename><surname>Hanzely</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Loka</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Takáč</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dmitry</forename><surname>Kamzolov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2410.23862</idno>
	</analytic>
	<monogr>
		<title level="m">1: Input: Grouped observations {x (m) } M m=1 2: Output: Estimated latent variables {ẑ (m) } M m=1 3: 4: # Random Initialization 5: Initialize encoders {En (m) } M m=1 and decoders {De (m) } M m=1 for each group 6: 7: # Encoder 8: Input: Grouped observations {x (m) } M m=1 9</title>
		<imprint>
			<publisher>Decode</publisher>
			<date type="published" when="2024">2024</date>
			<biblScope unit="volume">28</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Input: Estimated latent and exogenous variables in each group {ẑ (m) , η(m) } M m=1 29: Output: Reconstructed grouped features {x (m) } M m=1 30: for each group m = 1 to M do. to reconstruct features x(m) : x(m) = De (m) (ẑ (m) , η(m) ) 32: Compute reconstruction loss using MSE: L (m) Recon = MSE(x (m) , x (m) ) 33: end for</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>